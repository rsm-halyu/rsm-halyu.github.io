[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hang Lyu",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file. —\nAbout this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nHang Lyu\n\n\nApr 23, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "render_template.html",
    "href": "render_template.html",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "Lijia Yu\n\n\n\n\n\n halyu@ucsd.edu\n github.com/rsm-halyu\n +1 000-000-0000\nFor more information, please contact me via email.\n\n\n\n\n\nExperienced in statistical analysis, statistical learning models, and optimization methods.\nFull experience with next generation sequencing data analysis.\nHighly skilled in R, Bash, Perl, Python, LaTeX\n\n\n\n\nThis resume was made with the R package pagedown.\nLast updated on 2025-04-23."
  },
  {
    "objectID": "render_template.html#contact",
    "href": "render_template.html#contact",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "halyu@ucsd.edu\n github.com/rsm-halyu\n +1 000-000-0000\nFor more information, please contact me via email."
  },
  {
    "objectID": "render_template.html#skills",
    "href": "render_template.html#skills",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "Experienced in statistical analysis, statistical learning models, and optimization methods.\nFull experience with next generation sequencing data analysis.\nHighly skilled in R, Bash, Perl, Python, LaTeX"
  },
  {
    "objectID": "render_template.html#disclaimer",
    "href": "render_template.html#disclaimer",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "This resume was made with the R package pagedown.\nLast updated on 2025-04-23."
  },
  {
    "objectID": "render_template.html#title",
    "href": "render_template.html#title",
    "title": "Hang Lyu’s resume",
    "section": "Hang Lyu",
    "text": "Hang Lyu\n\nCurrently searching for a PhD student position\nPlease note that this is a real resume, and I’m really looking for a PhD student position at the moment. I made this resume because Yihui asked me if I’d like to test the pagedown package with my resume. If you are interested in my background and skills, please feel free to contact me."
  },
  {
    "objectID": "render_template.html#education",
    "href": "render_template.html#education",
    "title": "Hang Lyu’s resume",
    "section": "Education",
    "text": "Education\n\nBeijing University of Chemical Technology\nB.S. in Information and Computing Sciences\nBeijing, China\n2010\nThesis: Dyadic wavelet and its application in edge detection\n\n\nUniversity of Chinese Academy of Sciences\nM.S. in Bioinformatics\nBeijing, China\n2014\nThesis: A multi-omics study for intra-individual divergence of the distributions between mRNA isoforms in mammals"
  },
  {
    "objectID": "render_template.html#research-experience",
    "href": "render_template.html#research-experience",
    "title": "Hang Lyu’s resume",
    "section": "Research Experience",
    "text": "Research Experience\n\nGraduate Research Assistant\nBeijing Institute of Genomics, Chinese Academy of Sciences\nBeijing, China\n2011 - 2014\n\nPerformed computational biology research towards understanding regulation of alternative splicing in human and mouse transcriptome.\nFound EGFR pathway related mutations, aimed to understand the impacts of cancer mutations on EGFR signaling pathway.\n\n\n\nBioinformatican\nMy Health Gene Technology Co., Ltd.\nBeijing, China\n2015 - 2016\n\nInvestigated how cancer cells spread to other parts of the body at the single cell level.\n\n\n\nVisiting Scientist\nUniversity of Alabama at Birmingham\nAL, USA\n2016 - 2018\n\nInvestigated the role of mitochondria in development of cancer.\nInvestigated the evolution of genome architecture and its role in important evolutionary events.\nDetected thrombotic thrombocytopenic purpura related mutations in mutiple patients’ blood genome."
  },
  {
    "objectID": "render_template.html#professional-experience",
    "href": "render_template.html#professional-experience",
    "title": "Hang Lyu’s resume",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nData Scientist, intern\nSupStat Inc.\nBeijing, China\n2014\n\n\nTaught R language to beginners.\nWrote Shiny app demos.\nConverted statistical tutorials from SPSS to R language.\n\n\n\n\nBioinformatician\nMy Health Gene Technology Co., Ltd.\nBeijing, China\n2015 - 2016\n\n\nAnalyzed whole-exome sequencing data.\nWrote analysis pipelines of ChIP-seq, single cell DNA-seq and single cell RNA-seq.\nStudied tumor metastasis and wrote research reports.\nAlso did case studies to identify the genetic defect causing rare disease."
  },
  {
    "objectID": "render_template.html#teaching-experience",
    "href": "render_template.html#teaching-experience",
    "title": "Hang Lyu’s resume",
    "section": "Teaching Experience",
    "text": "Teaching Experience\n\nIntroduction to R Language for Beginners.\nInstructor of R and Data Mining Training Courses at SupStat Inc.\nBeijing, China\n2014\n\n\nComputational Biology and Bioinformatics.\nTeaching assistant of GBS CB2-201 courses at UAB\nAL, USA\n2016 - 2017"
  },
  {
    "objectID": "render_template.html#selected-publications-and-posters",
    "href": "render_template.html#selected-publications-and-posters",
    "title": "Hang Lyu’s resume",
    "section": "Selected Publications and Posters",
    "text": "Selected Publications and Posters\n\nGenetic and epigenetic signals are found predictive to the distribution of intra-individual divergence of alternative splicing.\nPoster for 2013 International Conference of Genomics\nQingdao, China\n2014\nYu L, Chen B, Zhang Z.\n\n\nESCRT-0 complex modulates Rbf mutant cell survival by regulating Rhomboid endosomal trafficking and EGFR signaling.\nJ Cell Sci. 2016 May 15;129(10):2075-84.\nN/A\n2016\nSheng Z, Yu L, Zhang T, Pei X, Li X, Zhang Z and Du W."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nt-test results based on class slide formula: mrm2: Mean (Treatment): 13.012 Mean (Control): 12.998 Manual t-stat: 0.1195\nhpa: Mean (Treatment): 59.599 Mean (Control): 58.960 Manual t-stat: 0.9731\nfreq: Mean (Treatment): 8.036 Mean (Control): 8.047 Manual t-stat: -0.1086\nLinear regression results: mrm2 ~ treatment: Coefficient: 0.0137 p-value: 0.9049\nhpa ~ treatment: Coefficient: 0.6389 p-value: 0.3438\nfreq ~ treatment: Coefficient: -0.0117 p-value: 0.9135\nAnswer for Balance Test:\nIn order to test whether the randomization successfully balanced key pre-treatment variables, I conducted both manual t-tests (using the class slide formula) and linear regressions comparing treatment and control groups on mrm2, hpa, and freq.\nIn these cases, the t-statistics were small and p-values were above 0.05, suggesting that there’s no statistically significant differences between the groups. This confirms that randomization was successful.\nThese results aligns with Table 1 in paper, which further confirms that the treatment and control groups were balanced on observable characteristics before the intervention."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\n\n\nT-test results: t-statistic: 3.2095 p-value: 0.0013\n\n\n\nAnswer for Experimental Results:\nA t-test on the binary outcome showed that people in the treatment group were more likely to donate than those in the control group, and this difference was statistically significant (p-value = 0.0013). A simple linear regression gave the same result: the treatment group had a higher donation rate.\nThese results match the findings in Table 2A of the paper, showing that just being assigned to the treatment group increased the chance of giving.\nAlso, regarding the probit regression to model whether someone donated or not, the results consistent with Table 3, Column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\nT-test: 2:1 vs 1:1 Rate (1:1): 0.02075 Rate (2:1): 0.02263 Difference: 0.00188 p-value: 0.33453\nT-test: 3:1 vs 2:1 Rate (2:1): 0.02263 Rate (3:1): 0.02273 Difference: 0.00010 p-value: 0.96003\nAnswer for A:\nThe p-values for both comparisons (p = 0.33 for 2:1 vs 1:1, p = 0.96 for 3:1 vs 2:1) show that these differences are not statistically significant.\nThis supports the authors’ comment on page 8 that “figures suggest” higher match ratios do not lead to significantly higher response rates.\n\n\n\nCoefficient p-value\nratio1 0.02075 0.0\nratio2 0.02263 0.0\nratio3 0.02273 0.0\nAnswer for B:\nIt indicates that the average donation rate for each group and show that all three are statistically significant.\n\n\n\nResponse Rate Differences (Direct from Data): 2:1 - 1:1 = 0.00188 3:1 - 2:1 = 0.00010\nResponse Rate Differences (From Regression Coefficients): 2:1 - 1:1 = 0.00188 3:1 - 2:1 = 0.00010\nAnswer for C:\nThe response rate increased by 0.00188 from the 1:1 to the 2:1 match ratio, and by 0.00010 from the 2:1 to the 3:1 ratio. These results were identical when using regression coefficients. The differences are minimal, indicating that larger match ratios do not meaningfully increase the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nA:\n{‘T-test p-value’: 0.05509, ‘Treatment group mean’: 0.97, ‘Control group mean’: 0.81, ‘Mean difference’: 0.15, ‘Regression coefficient’: 0.15, ‘Regression p-value’: 0.06282}\nAnswer for A:\nT-test and linear regression both show that the average donation amount was $0.15 higher in the treatment group than in the control group ($0.97 vs $0.81).\nThe difference is marginally statistically significant (t-test p = 0.055, regression p = 0.063), suggesting that the treatment may have increased donation amounts slightly.\n\n\n\n{‘Treatment group mean (donors only)’: 43.87, ‘Control group mean (donors only)’: 45.54, ‘Mean difference’: -1.67, ‘Regression coefficient’: -1.67, ‘Regression p-value’: 0.56148}\nAnswer for B:\nWhen restricting the analysis to only those who donated, the average donation was actually $1.67 lower in the treatment group compared to the control group ($43.87 vs $45.54). The regression confirms this difference (coefficient = -1.67), but the effect is not statistically significant (p = 0.561).\nThis suggests that, conditional on donating, the presence of a matching grant did not lead to larger donation amounts. While the treatment was randomly assigned, this analysis is not causal because it’s conditional on post-treatment behavior (donating)."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nAnswer: The cumulative average steadily approaches the true difference of 0.004, confirming the Law of Large Numbers.\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\nAnswer: As the sample size increases from 50 to 1000, the distribution of average differences becomes narrower and more centered around the true value of 0.004. In the smaller sample (n=50), the distribution is wider and zero is relatively close to the center. But as the sample size grows, zero moves further into the tail of the distribution."
  },
  {
    "objectID": "blog/project3/hw1_questions.html",
    "href": "blog/project3/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including the research areas of Balance Test, Experimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution), and Simulation Experiment (Central Limit Theorem)."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#introduction",
    "href": "blog/project3/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including the research areas of Balance Test, Experimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution), and Simulation Experiment (Central Limit Theorem)."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#data",
    "href": "blog/project3/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nimport pandas as pd\n\ndata_path = \"karlan_list_2007.dta\"\ndf_karlan = pd.read_stata(data_path)\n\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy import stats\n\nbalance_vars = ['mrm2', 'hpa', 'freq']\ndf_clean = df_karlan[['treatment'] + balance_vars].dropna()\n\n# t-test using class slide formula\nprint(\"t-test results based on class slide formula:\")\nfor var in balance_vars:\n    group_treat = df_clean[df_clean['treatment'] == 1][var]\n    group_ctrl = df_clean[df_clean['treatment'] == 0][var]\n\n    x_t = group_treat.mean()\n    x_c = group_ctrl.mean()\n    s_t = group_treat.std(ddof=1)\n    s_c = group_ctrl.std(ddof=1)\n    n_t = group_treat.shape[0]\n    n_c = group_ctrl.shape[0]\n\n    t_manual = (x_t - x_c) / np.sqrt((s_t**2 / n_t) + (s_c**2 / n_c))\n\n    print(f\"{var}:\")\n    print(f\"  Mean (Treatment): {x_t:.3f}\")\n    print(f\"  Mean (Control):   {x_c:.3f}\")\n    print(f\"  Manual t-stat:    {t_manual:.4f}\\n\")\n\nt-test results based on class slide formula:\nmrm2:\n  Mean (Treatment): 13.012\n  Mean (Control):   12.998\n  Manual t-stat:    0.1195\n\nhpa:\n  Mean (Treatment): 59.599\n  Mean (Control):   58.960\n  Manual t-stat:    0.9731\n\nfreq:\n  Mean (Treatment): 8.036\n  Mean (Control):   8.047\n  Manual t-stat:    -0.1086\n\n\n\n\n# linear regression comparison\nprint(\"Linear regression results:\")\nfor var in balance_vars:\n    y = df_clean[var]\n    X = sm.add_constant(df_clean['treatment'])  # Adds intercept term\n    model = sm.OLS(y, X).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n\n    print(f\"{var} ~ treatment:\")\n    print(f\"  Coefficient: {coef:.4f}\")\n    print(f\"  p-value:     {pval:.4f}\\n\")\n\nLinear regression results:\nmrm2 ~ treatment:\n  Coefficient: 0.0137\n  p-value:     0.9049\n\nhpa ~ treatment:\n  Coefficient: 0.6389\n  p-value:     0.3438\n\nfreq ~ treatment:\n  Coefficient: -0.0117\n  p-value:     0.9135\n\n\n\nAnalysis for Balance Test:\nIn order to test whether the randomization successfully balanced key pre-treatment variables, I conducted both manual t-tests (using the class slide formula) and linear regressions comparing treatment and control groups on mrm2, hpa, and freq.\nIn these cases, the t-statistics were small and p-values were above 0.05, suggesting that there’s no statistically significant differences between the groups. This confirms that randomization was successful.\nThese results aligns with Table 1 in paper, which further confirms that the treatment and control groups were balanced on observable characteristics before the intervention."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#experimental-results",
    "href": "blog/project3/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n# Barplot with two bars for treatment and control\nimport matplotlib.pyplot as plt\n\n# calculate donation rates\ndonation_rates = df_karlan.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\nplt.bar(labels, donation_rates, color=['gray', 'blue'])\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate: Treatment vs Control')\nplt.ylim(0, 0.03)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n# T-test between the treatment and control groups on the binary outcome\ndf_gave = df_karlan[['treatment', 'gave']].dropna()\n\n# t-test\ngave_treat = df_gave[df_gave['treatment'] == 1]['gave']\ngave_ctrl = df_gave[df_gave['treatment'] == 0]['gave']\nt_stat, p_val = stats.ttest_ind(gave_treat, gave_ctrl, equal_var=False)\n\nprint(\"T-test results:\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value:     {p_val:.4f}\\n\")\n\n# linear regression\nX = sm.add_constant(df_gave['treatment'])\ny = df_gave['gave']\nmodel_ols = sm.OLS(y, X).fit()\n\nT-test results:\n  t-statistic: 3.2095\n  p-value:     0.0013\n\n\n\n\n\n\n\n# probit regression\nprobit_model = sm.Probit(y, X).fit()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\nAnalysis for Experimental Results:\nA t-test on the binary outcome showed that people in the treatment group were more likely to donate than those in the control group, and this difference was statistically significant (p-value = 0.0013). A simple linear regression gave the same result: the treatment group had a higher donation rate.\nThese results match the findings in Table 2A of the paper, showing that just being assigned to the treatment group increased the chance of giving.\nAlso, regarding the probit regression to model whether someone donated or not, the results consistent with Table 3, Column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy import stats\n\ndf_match = df_karlan[df_karlan['treatment'] == 1].copy()\n\ndf_match['ratio1'] = (df_match['ratio'] == 1).astype(int)\ndf_match['ratio2'] = (df_match['ratio'] == 2).astype(int)\ndf_match['ratio3'] = (df_match['ratio'] == 3).astype(int)\n\ngave_1to1 = df_match[df_match['ratio1'] == 1]['gave']\ngave_2to1 = df_match[df_match['ratio2'] == 1]['gave']\ngave_3to1 = df_match[df_match['ratio3'] == 1]['gave']\n\n\n# run t-tests\nttest_2_vs_1 = stats.ttest_ind(gave_2to1, gave_1to1, equal_var=False)\nttest_3_vs_2 = stats.ttest_ind(gave_3to1, gave_2to1, equal_var=False)\n\n# calculate response rates\nrate_1to1 = gave_1to1.mean()\nrate_2to1 = gave_2to1.mean()\nrate_3to1 = gave_3to1.mean()\n\nprint(\"T-test: 2:1 vs 1:1\")\nprint(f\"  Rate (1:1): {rate_1to1:.5f}\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Difference: {rate_2to1 - rate_1to1:.5f}\")\nprint(f\"  p-value:    {ttest_2_vs_1.pvalue:.5f}\\n\")\n\nprint(\"T-test: 3:1 vs 2:1\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Rate (3:1): {rate_3to1:.5f}\")\nprint(f\"  Difference: {rate_3to1 - rate_2to1:.5f}\")\nprint(f\"  p-value:    {ttest_3_vs_2.pvalue:.5f}\")\n\nT-test: 2:1 vs 1:1\n  Rate (1:1): 0.02075\n  Rate (2:1): 0.02263\n  Difference: 0.00188\n  p-value:    0.33453\n\nT-test: 3:1 vs 2:1\n  Rate (2:1): 0.02263\n  Rate (3:1): 0.02273\n  Difference: 0.00010\n  p-value:    0.96003\n\n\nAnalysis for A:\nThe p-values for both comparisons (p = 0.33 for 2:1 vs 1:1, p = 0.96 for 3:1 vs 2:1) show that these differences are not statistically significant.\nThis supports the authors’ comment on page 8 that “figures suggest” higher match ratios do not lead to significantly higher response rates.\n\n\n\n\nX = df_match[['ratio1', 'ratio2', 'ratio3']]\ny = df_match['gave']\nmodel_ratios = sm.OLS(y, X).fit()\n\nCoefficient p-value\nratio1 0.02075 0.0\nratio2 0.02263 0.0\nratio3 0.02273 0.0\nAnalysis for B:\nIt indicates that the average donation rate for each group and show that all three are statistically significant.\n\n\n\n\n# directly from data\nrate_diff_2_vs_1_data = rate_2to1 - rate_1to1\nrate_diff_3_vs_2_data = rate_3to1 - rate_2to1\n\n# from regression coefficients\ncoef_diff_2_vs_1 = model_ratios.params['ratio2'] - model_ratios.params['ratio1']\ncoef_diff_3_vs_2 = model_ratios.params['ratio3'] - model_ratios.params['ratio2']\n\nprint(\"Response Rate Differences (Direct from Data):\")\nprint(f\"  2:1 - 1:1 = {rate_diff_2_vs_1_data:.5f}\")\nprint(f\"  3:1 - 2:1 = {rate_diff_3_vs_2_data:.5f}\\n\")\n\nprint(\"Response Rate Differences (From Regression Coefficients):\")\nprint(f\"  2:1 - 1:1 = {coef_diff_2_vs_1:.5f}\")\nprint(f\"  3:1 - 2:1 = {coef_diff_3_vs_2:.5f}\")\n\nResponse Rate Differences (Direct from Data):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\nResponse Rate Differences (From Regression Coefficients):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\n\nAnalysis for C:\nThe response rate increased by 0.00188 from the 1:1 to the 2:1 match ratio, and by 0.00010 from the 2:1 to the 3:1 ratio. These results were identical when using regression coefficients. The differences are minimal, indicating that larger match ratios do not meaningfully increase the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nA:\n\ndf_amount = df_karlan[['treatment', 'amount']].dropna()\n\n# run a t-test on donation amount between treatment and control\namount_treat = df_amount[df_amount['treatment'] == 1]['amount']\namount_ctrl = df_amount[df_amount['treatment'] == 0]['amount']\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\n\nX = sm.add_constant(df_amount['treatment'])\ny = df_amount['amount']\nmodel_amount = sm.OLS(y, X).fit()\n\nreg_coef = model_amount.params['treatment']\nreg_pval = model_amount.pvalues['treatment']\nmean_treat = amount_treat.mean()\nmean_ctrl = amount_ctrl.mean()\nmean_diff = mean_treat - mean_ctrl\n\n\n{\n    \"T-test p-value\": round(p_val, 5),\n    \"Treatment group mean\": round(mean_treat, 2),\n    \"Control group mean\": round(mean_ctrl, 2),\n    \"Mean difference\": round(mean_diff, 2),\n    \"Regression coefficient\": round(reg_coef, 2),\n    \"Regression p-value\": round(reg_pval, 5)\n}\n\n{'T-test p-value': 0.05509,\n 'Treatment group mean': 0.97,\n 'Control group mean': 0.81,\n 'Mean difference': 0.15,\n 'Regression coefficient': 0.15,\n 'Regression p-value': 0.06282}\n\n\nAnalysis for A:\nT-test and linear regression both show that the average donation amount was $0.15 higher in the treatment group than in the control group ($0.97 vs $0.81).\nThe difference is marginally statistically significant (t-test p = 0.055, regression p = 0.063), suggesting that the treatment may have increased donation amounts slightly.\n\n\n\n\ndf_donors = df_karlan[(df_karlan['amount'] &gt; 0)][['treatment', 'amount']]\n\n# run regression: amount ~ treatment (conditional on donating)\nX_donors = sm.add_constant(df_donors['treatment'])\ny_donors = df_donors['amount']\nmodel_donors = sm.OLS(y_donors, X_donors).fit()\n\nreg_coef_donors = model_donors.params['treatment']\nreg_pval_donors = model_donors.pvalues['treatment']\nmean_treat_donors = df_donors[df_donors['treatment'] == 1]['amount'].mean()\nmean_ctrl_donors = df_donors[df_donors['treatment'] == 0]['amount'].mean()\nmean_diff_donors = mean_treat_donors - mean_ctrl_donors\n\n{\n    \"Treatment group mean (donors only)\": round(mean_treat_donors, 2),\n    \"Control group mean (donors only)\": round(mean_ctrl_donors, 2),\n    \"Mean difference\": round(mean_diff_donors, 2),\n    \"Regression coefficient\": round(reg_coef_donors, 2),\n    \"Regression p-value\": round(reg_pval_donors, 5)\n}\n\n{'Treatment group mean (donors only)': 43.87,\n 'Control group mean (donors only)': 45.54,\n 'Mean difference': -1.67,\n 'Regression coefficient': -1.67,\n 'Regression p-value': 0.56148}\n\n\nAnalysis for B:\nWhen restricting the analysis to only those who donated, the average donation was actually $1.67 lower in the treatment group compared to the control group ($43.87 vs $45.54). The regression confirms this difference (coefficient = -1.67), but the effect is not statistically significant (p = 0.561).\nThis suggests that, conditional on donating, the presence of a matching grant did not lead to larger donation amounts. While the treatment was randomly assigned, this analysis is not causal because it’s conditional on post-treatment behavior (donating).\n\nimport matplotlib.pyplot as plt\n\n# create subsets for donors in treatment and control\ndonors_treat = df_karlan[(df_karlan['treatment'] == 1) & (df_karlan['amount'] &gt; 0)]['amount']\ndonors_ctrl = df_karlan[(df_karlan['treatment'] == 0) & (df_karlan['amount'] &gt; 0)]['amount']\n\n\n# plot for treatment group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_treat, bins=30, color='skyblue', edgecolor='black')\nplt.axvline(donors_treat.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# plot for control group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_ctrl, bins=30, color='lightgreen', edgecolor='black')\nplt.axvline(donors_ctrl.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/project3/hw1_questions.html#simulation-experiment",
    "href": "blog/project3/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# simulate 100,000 draws from control (p = 0.018) and treatment (p = 0.022)\nn_draws = 100_000\ncontrol_draws = np.random.binomial(1, 0.018, size=n_draws)\ntreatment_draws = np.random.binomial(1, 0.022, size=n_draws)\n\ndiffs = treatment_draws - control_draws\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_draws + 1)\n\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Avg. Difference')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Differences')\nplt.title('Cumulative average of differences')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis: The cumulative average steadily approaches the true difference of 0.004, confirming the Law of Large Numbers.\n\n\nCentral Limit Theorem\n\ndef simulate_clt_differences(sample_size, n_simulations=1000, p_control=0.018, p_treat=0.022):\n    differences = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, size=sample_size)\n        treatment_sample = np.random.binomial(1, p_treat, size=sample_size)\n        diff = treatment_sample.mean() - control_sample.mean()\n        differences.append(diff)\n    return differences\n\nsample_sizes = [50, 200, 500, 1000]\n\nfor size in sample_sizes:\n    diffs = simulate_clt_differences(size)\n    plt.figure(figsize=(6, 4))\n    plt.hist(diffs, bins=30, color='lightgray', edgecolor='black')\n    plt.axvline(0, color='red', linestyle='--', label='Zero')\n    plt.axvline(0.004, color='blue', linestyle='--', label='True Diff (0.004)')\n    plt.title(f'Sample Size = {size}')\n    plt.xlabel('Avg. Difference (Treat - Control)')\n    plt.ylabel('Frequency')\n    plt.xlim(-0.06, 0.06) \n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis: As the sample size increases from 50 to 1000, the distribution of average differences becomes narrower and more centered around the true value of 0.004. In the smaller sample (n=50), the distribution is wider and zero is relatively close to the center. But as the sample size grows, zero moves further into the tail of the distribution."
  },
  {
    "objectID": "blog/project3/index.html",
    "href": "blog/project3/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including delve into the research areas of:\n\nBalance Test\nExperimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution)\nSimulation Experiment (Central Limit Theorem)"
  },
  {
    "objectID": "blog/project3/index.html#introduction",
    "href": "blog/project3/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including delve into the research areas of:\n\nBalance Test\nExperimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution)\nSimulation Experiment (Central Limit Theorem)"
  },
  {
    "objectID": "blog/project3/index.html#data",
    "href": "blog/project3/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\n\nCode\nimport pandas as pd\n\ndata_path = \"karlan_list_2007.dta\"\ndf_karlan = pd.read_stata(data_path)\n\n\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy import stats\n\nbalance_vars = ['mrm2', 'hpa', 'freq']\ndf_clean = df_karlan[['treatment'] + balance_vars].dropna()\n\n# t-test using class slide formula\nprint(\"t-test results based on class slide formula:\")\nfor var in balance_vars:\n    group_treat = df_clean[df_clean['treatment'] == 1][var]\n    group_ctrl = df_clean[df_clean['treatment'] == 0][var]\n\n    x_t = group_treat.mean()\n    x_c = group_ctrl.mean()\n    s_t = group_treat.std(ddof=1)\n    s_c = group_ctrl.std(ddof=1)\n    n_t = group_treat.shape[0]\n    n_c = group_ctrl.shape[0]\n\n    t_manual = (x_t - x_c) / np.sqrt((s_t**2 / n_t) + (s_c**2 / n_c))\n\n    print(f\"{var}:\")\n    print(f\"  Mean (Treatment): {x_t:.3f}\")\n    print(f\"  Mean (Control):   {x_c:.3f}\")\n    print(f\"  Manual t-stat:    {t_manual:.4f}\\n\")\n\nt-test results based on class slide formula:\nmrm2:\n  Mean (Treatment): 13.012\n  Mean (Control):   12.998\n  Manual t-stat:    0.1195\n\nhpa:\n  Mean (Treatment): 59.599\n  Mean (Control):   58.960\n  Manual t-stat:    0.9731\n\nfreq:\n  Mean (Treatment): 8.036\n  Mean (Control):   8.047\n  Manual t-stat:    -0.1086\n\n\n\n\n# linear regression comparison\nprint(\"Linear regression results:\")\nfor var in balance_vars:\n    y = df_clean[var]\n    X = sm.add_constant(df_clean['treatment'])  # Adds intercept term\n    model = sm.OLS(y, X).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n\n    print(f\"{var} ~ treatment:\")\n    print(f\"  Coefficient: {coef:.4f}\")\n    print(f\"  p-value:     {pval:.4f}\\n\")\n\nLinear regression results:\nmrm2 ~ treatment:\n  Coefficient: 0.0137\n  p-value:     0.9049\n\nhpa ~ treatment:\n  Coefficient: 0.6389\n  p-value:     0.3438\n\nfreq ~ treatment:\n  Coefficient: -0.0117\n  p-value:     0.9135\n\n\n\nAnalysis for Balance Test:\nIn order to test whether the randomization successfully balanced key pre-treatment variables, I conducted both manual t-tests (using the class slide formula) and linear regressions comparing treatment and control groups on mrm2, hpa, and freq.\nIn these cases, the t-statistics were small and p-values were above 0.05, suggesting that there’s no statistically significant differences between the groups. This confirms that randomization was successful.\nThese results aligns with Table 1 in paper, which further confirms that the treatment and control groups were balanced on observable characteristics before the intervention."
  },
  {
    "objectID": "blog/project3/index.html#experimental-results",
    "href": "blog/project3/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n# Barplot with two bars for treatment and control\nimport matplotlib.pyplot as plt\n\n# calculate donation rates\ndonation_rates = df_karlan.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\nplt.bar(labels, donation_rates, color=['gray', 'blue'])\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate: Treatment vs Control')\nplt.ylim(0, 0.03)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n# T-test between the treatment and control groups on the binary outcome\ndf_gave = df_karlan[['treatment', 'gave']].dropna()\n\n# t-test\ngave_treat = df_gave[df_gave['treatment'] == 1]['gave']\ngave_ctrl = df_gave[df_gave['treatment'] == 0]['gave']\nt_stat, p_val = stats.ttest_ind(gave_treat, gave_ctrl, equal_var=False)\n\nprint(\"T-test results:\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value:     {p_val:.4f}\\n\")\n\n# linear regression\nX = sm.add_constant(df_gave['treatment'])\ny = df_gave['gave']\nmodel_ols = sm.OLS(y, X).fit()\n\nT-test results:\n  t-statistic: 3.2095\n  p-value:     0.0013\n\n\n\n\n\n\n\n# probit regression\nprobit_model = sm.Probit(y, X).fit()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\nAnalysis for Charitable Contribution Made:\nA t-test on the binary outcome showed that people in the treatment group were more likely to donate than those in the control group, and this difference was statistically significant (p-value = 0.0013). A simple linear regression gave the same result: the treatment group had a higher donation rate.\nThese results match the findings in Table 2A of the paper, showing that just being assigned to the treatment group increased the chance of giving.\nAlso, regarding the probit regression to model whether someone donated or not, the results consistent with Table 3, Column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy import stats\n\ndf_match = df_karlan[df_karlan['treatment'] == 1].copy()\n\ndf_match['ratio1'] = (df_match['ratio'] == 1).astype(int)\ndf_match['ratio2'] = (df_match['ratio'] == 2).astype(int)\ndf_match['ratio3'] = (df_match['ratio'] == 3).astype(int)\n\ngave_1to1 = df_match[df_match['ratio1'] == 1]['gave']\ngave_2to1 = df_match[df_match['ratio2'] == 1]['gave']\ngave_3to1 = df_match[df_match['ratio3'] == 1]['gave']\n\n\n# run t-tests\nttest_2_vs_1 = stats.ttest_ind(gave_2to1, gave_1to1, equal_var=False)\nttest_3_vs_2 = stats.ttest_ind(gave_3to1, gave_2to1, equal_var=False)\n\n# calculate response rates\nrate_1to1 = gave_1to1.mean()\nrate_2to1 = gave_2to1.mean()\nrate_3to1 = gave_3to1.mean()\n\nprint(\"T-test: 2:1 vs 1:1\")\nprint(f\"  Rate (1:1): {rate_1to1:.5f}\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Difference: {rate_2to1 - rate_1to1:.5f}\")\nprint(f\"  p-value:    {ttest_2_vs_1.pvalue:.5f}\\n\")\n\nprint(\"T-test: 3:1 vs 2:1\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Rate (3:1): {rate_3to1:.5f}\")\nprint(f\"  Difference: {rate_3to1 - rate_2to1:.5f}\")\nprint(f\"  p-value:    {ttest_3_vs_2.pvalue:.5f}\")\n\nT-test: 2:1 vs 1:1\n  Rate (1:1): 0.02075\n  Rate (2:1): 0.02263\n  Difference: 0.00188\n  p-value:    0.33453\n\nT-test: 3:1 vs 2:1\n  Rate (2:1): 0.02263\n  Rate (3:1): 0.02273\n  Difference: 0.00010\n  p-value:    0.96003\n\n\nAnalysis for A:\nThe p-values for both comparisons (p = 0.33 for 2:1 vs 1:1, p = 0.96 for 3:1 vs 2:1) show that these differences are not statistically significant.\nThis supports the authors’ comment on page 8 that “figures suggest” higher match ratios do not lead to significantly higher response rates.\n\n\n\n\nX = df_match[['ratio1', 'ratio2', 'ratio3']]\ny = df_match['gave']\nmodel_ratios = sm.OLS(y, X).fit()\n\nCoefficient p-value\nratio1 0.02075 0.0\nratio2 0.02263 0.0\nratio3 0.02273 0.0\nAnalysis for B:\nIt indicates that the average donation rate for each group and show that all three are statistically significant.\n\n\n\n\n# directly from data\nrate_diff_2_vs_1_data = rate_2to1 - rate_1to1\nrate_diff_3_vs_2_data = rate_3to1 - rate_2to1\n\n# from regression coefficients\ncoef_diff_2_vs_1 = model_ratios.params['ratio2'] - model_ratios.params['ratio1']\ncoef_diff_3_vs_2 = model_ratios.params['ratio3'] - model_ratios.params['ratio2']\n\nprint(\"Response Rate Differences (Direct from Data):\")\nprint(f\"  2:1 - 1:1 = {rate_diff_2_vs_1_data:.5f}\")\nprint(f\"  3:1 - 2:1 = {rate_diff_3_vs_2_data:.5f}\\n\")\n\nprint(\"Response Rate Differences (From Regression Coefficients):\")\nprint(f\"  2:1 - 1:1 = {coef_diff_2_vs_1:.5f}\")\nprint(f\"  3:1 - 2:1 = {coef_diff_3_vs_2:.5f}\")\n\nResponse Rate Differences (Direct from Data):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\nResponse Rate Differences (From Regression Coefficients):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\n\nAnalysis for C:\nThe response rate increased by 0.00188 from the 1:1 to the 2:1 match ratio, and by 0.00010 from the 2:1 to the 3:1 ratio. These results were identical when using regression coefficients. The differences are minimal, indicating that larger match ratios do not meaningfully increase the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n\n\n\ndf_amount = df_karlan[['treatment', 'amount']].dropna()\n\n# run a t-test on donation amount between treatment and control\namount_treat = df_amount[df_amount['treatment'] == 1]['amount']\namount_ctrl = df_amount[df_amount['treatment'] == 0]['amount']\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\n\nX = sm.add_constant(df_amount['treatment'])\ny = df_amount['amount']\nmodel_amount = sm.OLS(y, X).fit()\n\nreg_coef = model_amount.params['treatment']\nreg_pval = model_amount.pvalues['treatment']\nmean_treat = amount_treat.mean()\nmean_ctrl = amount_ctrl.mean()\nmean_diff = mean_treat - mean_ctrl\n\n\n{\n    \"T-test p-value\": round(p_val, 5),\n    \"Treatment group mean\": round(mean_treat, 2),\n    \"Control group mean\": round(mean_ctrl, 2),\n    \"Mean difference\": round(mean_diff, 2),\n    \"Regression coefficient\": round(reg_coef, 2),\n    \"Regression p-value\": round(reg_pval, 5)\n}\n\n{'T-test p-value': 0.05509,\n 'Treatment group mean': 0.97,\n 'Control group mean': 0.81,\n 'Mean difference': 0.15,\n 'Regression coefficient': 0.15,\n 'Regression p-value': 0.06282}\n\n\nAnalysis for A:\nT-test and linear regression both show that the average donation amount was $0.15 higher in the treatment group than in the control group ($0.97 vs $0.81).\nThe difference is marginally statistically significant (t-test p = 0.055, regression p = 0.063), suggesting that the treatment may have increased donation amounts slightly.\n\n\n\n\ndf_donors = df_karlan[(df_karlan['amount'] &gt; 0)][['treatment', 'amount']]\n\n# run regression: amount ~ treatment (conditional on donating)\nX_donors = sm.add_constant(df_donors['treatment'])\ny_donors = df_donors['amount']\nmodel_donors = sm.OLS(y_donors, X_donors).fit()\n\nreg_coef_donors = model_donors.params['treatment']\nreg_pval_donors = model_donors.pvalues['treatment']\nmean_treat_donors = df_donors[df_donors['treatment'] == 1]['amount'].mean()\nmean_ctrl_donors = df_donors[df_donors['treatment'] == 0]['amount'].mean()\nmean_diff_donors = mean_treat_donors - mean_ctrl_donors\n\n{\n    \"Treatment group mean (donors only)\": round(mean_treat_donors, 2),\n    \"Control group mean (donors only)\": round(mean_ctrl_donors, 2),\n    \"Mean difference\": round(mean_diff_donors, 2),\n    \"Regression coefficient\": round(reg_coef_donors, 2),\n    \"Regression p-value\": round(reg_pval_donors, 5)\n}\n\n{'Treatment group mean (donors only)': 43.87,\n 'Control group mean (donors only)': 45.54,\n 'Mean difference': -1.67,\n 'Regression coefficient': -1.67,\n 'Regression p-value': 0.56148}\n\n\nAnalysis for B:\nWhen restricting the analysis to only those who donated, the average donation was actually $1.67 lower in the treatment group compared to the control group ($43.87 vs $45.54). The regression confirms this difference (coefficient = -1.67), but the effect is not statistically significant (p = 0.561).\nThis suggests that, conditional on donating, the presence of a matching grant did not lead to larger donation amounts. While the treatment was randomly assigned, this analysis is not causal because it’s conditional on post-treatment behavior (donating).\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# create subsets for donors in treatment and control\ndonors_treat = df_karlan[(df_karlan['treatment'] == 1) & (df_karlan['amount'] &gt; 0)]['amount']\ndonors_ctrl = df_karlan[(df_karlan['treatment'] == 0) & (df_karlan['amount'] &gt; 0)]['amount']\n\n\n# plot for treatment group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_treat, bins=30, color='skyblue', edgecolor='black')\nplt.axvline(donors_treat.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# plot for control group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_ctrl, bins=30, color='lightgreen', edgecolor='black')\nplt.axvline(donors_ctrl.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/project3/index.html#simulation-experiment",
    "href": "blog/project3/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# simulate 100,000 draws from control (p = 0.018) and treatment (p = 0.022)\nn_draws = 100_000\ncontrol_draws = np.random.binomial(1, 0.018, size=n_draws)\ntreatment_draws = np.random.binomial(1, 0.022, size=n_draws)\n\ndiffs = treatment_draws - control_draws\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_draws + 1)\n\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Avg. Difference')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Differences')\nplt.title('Cumulative average of differences')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis: The cumulative average steadily approaches the true difference of 0.004, confirming the Law of Large Numbers.\n\n\nCentral Limit Theorem\n\ndef simulate_clt_differences(sample_size, n_simulations=1000, p_control=0.018, p_treat=0.022):\n    differences = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, size=sample_size)\n        treatment_sample = np.random.binomial(1, p_treat, size=sample_size)\n        diff = treatment_sample.mean() - control_sample.mean()\n        differences.append(diff)\n    return differences\n\nsample_sizes = [50, 200, 500, 1000]\n\nfor size in sample_sizes:\n    diffs = simulate_clt_differences(size)\n    plt.figure(figsize=(6, 4))\n    plt.hist(diffs, bins=30, color='lightgray', edgecolor='black')\n    plt.axvline(0, color='red', linestyle='--', label='Zero')\n    plt.axvline(0.004, color='blue', linestyle='--', label='True Diff (0.004)')\n    plt.title(f'Sample Size = {size}')\n    plt.xlabel('Avg. Difference (Treat - Control)')\n    plt.ylabel('Frequency')\n    plt.xlim(-0.06, 0.06) \n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis: As the sample size increases from 50 to 1000, the distribution of average differences becomes narrower and more centered around the true value of 0.004. In the smaller sample (n=50), the distribution is wider and zero is relatively close to the center. But as the sample size grows, zero moves further into the tail of the distribution."
  }
]