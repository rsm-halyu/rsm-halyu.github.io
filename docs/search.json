[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hang Lyu",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file. —\nAbout this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nHang Lyu\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nHang Lyu\n\n\nApr 23, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "render_template.html",
    "href": "render_template.html",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "Lijia Yu\n\n\n\n\n\n halyu@ucsd.edu\n github.com/rsm-halyu\n +1 000-000-0000\nFor more information, please contact me via email.\n\n\n\n\n\nExperienced in statistical analysis, statistical learning models, and optimization methods.\nFull experience with next generation sequencing data analysis.\nHighly skilled in R, Bash, Perl, Python, LaTeX\n\n\n\n\nThis resume was made with the R package pagedown.\nLast updated on 2025-04-23."
  },
  {
    "objectID": "render_template.html#contact",
    "href": "render_template.html#contact",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "halyu@ucsd.edu\n github.com/rsm-halyu\n +1 000-000-0000\nFor more information, please contact me via email."
  },
  {
    "objectID": "render_template.html#skills",
    "href": "render_template.html#skills",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "Experienced in statistical analysis, statistical learning models, and optimization methods.\nFull experience with next generation sequencing data analysis.\nHighly skilled in R, Bash, Perl, Python, LaTeX"
  },
  {
    "objectID": "render_template.html#disclaimer",
    "href": "render_template.html#disclaimer",
    "title": "Hang Lyu’s resume",
    "section": "",
    "text": "This resume was made with the R package pagedown.\nLast updated on 2025-04-23."
  },
  {
    "objectID": "render_template.html#title",
    "href": "render_template.html#title",
    "title": "Hang Lyu’s resume",
    "section": "Hang Lyu",
    "text": "Hang Lyu\n\nCurrently searching for a PhD student position\nPlease note that this is a real resume, and I’m really looking for a PhD student position at the moment. I made this resume because Yihui asked me if I’d like to test the pagedown package with my resume. If you are interested in my background and skills, please feel free to contact me."
  },
  {
    "objectID": "render_template.html#education",
    "href": "render_template.html#education",
    "title": "Hang Lyu’s resume",
    "section": "Education",
    "text": "Education\n\nBeijing University of Chemical Technology\nB.S. in Information and Computing Sciences\nBeijing, China\n2010\nThesis: Dyadic wavelet and its application in edge detection\n\n\nUniversity of Chinese Academy of Sciences\nM.S. in Bioinformatics\nBeijing, China\n2014\nThesis: A multi-omics study for intra-individual divergence of the distributions between mRNA isoforms in mammals"
  },
  {
    "objectID": "render_template.html#research-experience",
    "href": "render_template.html#research-experience",
    "title": "Hang Lyu’s resume",
    "section": "Research Experience",
    "text": "Research Experience\n\nGraduate Research Assistant\nBeijing Institute of Genomics, Chinese Academy of Sciences\nBeijing, China\n2011 - 2014\n\nPerformed computational biology research towards understanding regulation of alternative splicing in human and mouse transcriptome.\nFound EGFR pathway related mutations, aimed to understand the impacts of cancer mutations on EGFR signaling pathway.\n\n\n\nBioinformatican\nMy Health Gene Technology Co., Ltd.\nBeijing, China\n2015 - 2016\n\nInvestigated how cancer cells spread to other parts of the body at the single cell level.\n\n\n\nVisiting Scientist\nUniversity of Alabama at Birmingham\nAL, USA\n2016 - 2018\n\nInvestigated the role of mitochondria in development of cancer.\nInvestigated the evolution of genome architecture and its role in important evolutionary events.\nDetected thrombotic thrombocytopenic purpura related mutations in mutiple patients’ blood genome."
  },
  {
    "objectID": "render_template.html#professional-experience",
    "href": "render_template.html#professional-experience",
    "title": "Hang Lyu’s resume",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nData Scientist, intern\nSupStat Inc.\nBeijing, China\n2014\n\n\nTaught R language to beginners.\nWrote Shiny app demos.\nConverted statistical tutorials from SPSS to R language.\n\n\n\n\nBioinformatician\nMy Health Gene Technology Co., Ltd.\nBeijing, China\n2015 - 2016\n\n\nAnalyzed whole-exome sequencing data.\nWrote analysis pipelines of ChIP-seq, single cell DNA-seq and single cell RNA-seq.\nStudied tumor metastasis and wrote research reports.\nAlso did case studies to identify the genetic defect causing rare disease."
  },
  {
    "objectID": "render_template.html#teaching-experience",
    "href": "render_template.html#teaching-experience",
    "title": "Hang Lyu’s resume",
    "section": "Teaching Experience",
    "text": "Teaching Experience\n\nIntroduction to R Language for Beginners.\nInstructor of R and Data Mining Training Courses at SupStat Inc.\nBeijing, China\n2014\n\n\nComputational Biology and Bioinformatics.\nTeaching assistant of GBS CB2-201 courses at UAB\nAL, USA\n2016 - 2017"
  },
  {
    "objectID": "render_template.html#selected-publications-and-posters",
    "href": "render_template.html#selected-publications-and-posters",
    "title": "Hang Lyu’s resume",
    "section": "Selected Publications and Posters",
    "text": "Selected Publications and Posters\n\nGenetic and epigenetic signals are found predictive to the distribution of intra-individual divergence of alternative splicing.\nPoster for 2013 International Conference of Genomics\nQingdao, China\n2014\nYu L, Chen B, Zhang Z.\n\n\nESCRT-0 complex modulates Rbf mutant cell survival by regulating Rhomboid endosomal trafficking and EGFR signaling.\nJ Cell Sci. 2016 May 15;129(10):2075-84.\nN/A\n2016\nSheng Z, Yu L, Zhang T, Pei X, Li X, Zhang Z and Du W."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nt-test results based on class slide formula: mrm2: Mean (Treatment): 13.012 Mean (Control): 12.998 Manual t-stat: 0.1195\nhpa: Mean (Treatment): 59.599 Mean (Control): 58.960 Manual t-stat: 0.9731\nfreq: Mean (Treatment): 8.036 Mean (Control): 8.047 Manual t-stat: -0.1086\nLinear regression results: mrm2 ~ treatment: Coefficient: 0.0137 p-value: 0.9049\nhpa ~ treatment: Coefficient: 0.6389 p-value: 0.3438\nfreq ~ treatment: Coefficient: -0.0117 p-value: 0.9135\nAnswer for Balance Test:\nIn order to test whether the randomization successfully balanced key pre-treatment variables, I conducted both manual t-tests (using the class slide formula) and linear regressions comparing treatment and control groups on mrm2, hpa, and freq.\nIn these cases, the t-statistics were small and p-values were above 0.05, suggesting that there’s no statistically significant differences between the groups. This confirms that randomization was successful.\nThese results aligns with Table 1 in paper, which further confirms that the treatment and control groups were balanced on observable characteristics before the intervention."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\n\n\nT-test results: t-statistic: 3.2095 p-value: 0.0013\n\n\n\nAnswer for Experimental Results:\nA t-test on the binary outcome showed that people in the treatment group were more likely to donate than those in the control group, and this difference was statistically significant (p-value = 0.0013). A simple linear regression gave the same result: the treatment group had a higher donation rate.\nThese results match the findings in Table 2A of the paper, showing that just being assigned to the treatment group increased the chance of giving.\nAlso, regarding the probit regression to model whether someone donated or not, the results consistent with Table 3, Column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\nT-test: 2:1 vs 1:1 Rate (1:1): 0.02075 Rate (2:1): 0.02263 Difference: 0.00188 p-value: 0.33453\nT-test: 3:1 vs 2:1 Rate (2:1): 0.02263 Rate (3:1): 0.02273 Difference: 0.00010 p-value: 0.96003\nAnswer for A:\nThe p-values for both comparisons (p = 0.33 for 2:1 vs 1:1, p = 0.96 for 3:1 vs 2:1) show that these differences are not statistically significant.\nThis supports the authors’ comment on page 8 that “figures suggest” higher match ratios do not lead to significantly higher response rates.\n\n\n\nCoefficient p-value\nratio1 0.02075 0.0\nratio2 0.02263 0.0\nratio3 0.02273 0.0\nAnswer for B:\nIt indicates that the average donation rate for each group and show that all three are statistically significant.\n\n\n\nResponse Rate Differences (Direct from Data): 2:1 - 1:1 = 0.00188 3:1 - 2:1 = 0.00010\nResponse Rate Differences (From Regression Coefficients): 2:1 - 1:1 = 0.00188 3:1 - 2:1 = 0.00010\nAnswer for C:\nThe response rate increased by 0.00188 from the 1:1 to the 2:1 match ratio, and by 0.00010 from the 2:1 to the 3:1 ratio. These results were identical when using regression coefficients. The differences are minimal, indicating that larger match ratios do not meaningfully increase the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nA:\n{‘T-test p-value’: 0.05509, ‘Treatment group mean’: 0.97, ‘Control group mean’: 0.81, ‘Mean difference’: 0.15, ‘Regression coefficient’: 0.15, ‘Regression p-value’: 0.06282}\nAnswer for A:\nT-test and linear regression both show that the average donation amount was $0.15 higher in the treatment group than in the control group ($0.97 vs $0.81).\nThe difference is marginally statistically significant (t-test p = 0.055, regression p = 0.063), suggesting that the treatment may have increased donation amounts slightly.\n\n\n\n{‘Treatment group mean (donors only)’: 43.87, ‘Control group mean (donors only)’: 45.54, ‘Mean difference’: -1.67, ‘Regression coefficient’: -1.67, ‘Regression p-value’: 0.56148}\nAnswer for B:\nWhen restricting the analysis to only those who donated, the average donation was actually $1.67 lower in the treatment group compared to the control group ($43.87 vs $45.54). The regression confirms this difference (coefficient = -1.67), but the effect is not statistically significant (p = 0.561).\nThis suggests that, conditional on donating, the presence of a matching grant did not lead to larger donation amounts. While the treatment was randomly assigned, this analysis is not causal because it’s conditional on post-treatment behavior (donating)."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nAnswer: The cumulative average steadily approaches the true difference of 0.004, confirming the Law of Large Numbers.\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\nAnswer: As the sample size increases from 50 to 1000, the distribution of average differences becomes narrower and more centered around the true value of 0.004. In the smaller sample (n=50), the distribution is wider and zero is relatively close to the center. But as the sample size grows, zero moves further into the tail of the distribution."
  },
  {
    "objectID": "blog/project3/hw1_questions.html",
    "href": "blog/project3/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including the research areas of Balance Test, Experimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution), and Simulation Experiment (Central Limit Theorem)."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#introduction",
    "href": "blog/project3/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including the research areas of Balance Test, Experimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution), and Simulation Experiment (Central Limit Theorem)."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#data",
    "href": "blog/project3/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nimport pandas as pd\n\ndata_path = \"karlan_list_2007.dta\"\ndf_karlan = pd.read_stata(data_path)\n\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy import stats\n\nbalance_vars = ['mrm2', 'hpa', 'freq']\ndf_clean = df_karlan[['treatment'] + balance_vars].dropna()\n\n# t-test using class slide formula\nprint(\"t-test results based on class slide formula:\")\nfor var in balance_vars:\n    group_treat = df_clean[df_clean['treatment'] == 1][var]\n    group_ctrl = df_clean[df_clean['treatment'] == 0][var]\n\n    x_t = group_treat.mean()\n    x_c = group_ctrl.mean()\n    s_t = group_treat.std(ddof=1)\n    s_c = group_ctrl.std(ddof=1)\n    n_t = group_treat.shape[0]\n    n_c = group_ctrl.shape[0]\n\n    t_manual = (x_t - x_c) / np.sqrt((s_t**2 / n_t) + (s_c**2 / n_c))\n\n    print(f\"{var}:\")\n    print(f\"  Mean (Treatment): {x_t:.3f}\")\n    print(f\"  Mean (Control):   {x_c:.3f}\")\n    print(f\"  Manual t-stat:    {t_manual:.4f}\\n\")\n\nt-test results based on class slide formula:\nmrm2:\n  Mean (Treatment): 13.012\n  Mean (Control):   12.998\n  Manual t-stat:    0.1195\n\nhpa:\n  Mean (Treatment): 59.599\n  Mean (Control):   58.960\n  Manual t-stat:    0.9731\n\nfreq:\n  Mean (Treatment): 8.036\n  Mean (Control):   8.047\n  Manual t-stat:    -0.1086\n\n\n\n\n# linear regression comparison\nprint(\"Linear regression results:\")\nfor var in balance_vars:\n    y = df_clean[var]\n    X = sm.add_constant(df_clean['treatment'])  # Adds intercept term\n    model = sm.OLS(y, X).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n\n    print(f\"{var} ~ treatment:\")\n    print(f\"  Coefficient: {coef:.4f}\")\n    print(f\"  p-value:     {pval:.4f}\\n\")\n\nLinear regression results:\nmrm2 ~ treatment:\n  Coefficient: 0.0137\n  p-value:     0.9049\n\nhpa ~ treatment:\n  Coefficient: 0.6389\n  p-value:     0.3438\n\nfreq ~ treatment:\n  Coefficient: -0.0117\n  p-value:     0.9135\n\n\n\nAnalysis for Balance Test:\nIn order to test whether the randomization successfully balanced key pre-treatment variables, I conducted both manual t-tests (using the class slide formula) and linear regressions comparing treatment and control groups on mrm2, hpa, and freq.\nIn these cases, the t-statistics were small and p-values were above 0.05, suggesting that there’s no statistically significant differences between the groups. This confirms that randomization was successful.\nThese results aligns with Table 1 in paper, which further confirms that the treatment and control groups were balanced on observable characteristics before the intervention."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#experimental-results",
    "href": "blog/project3/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n# Barplot with two bars for treatment and control\nimport matplotlib.pyplot as plt\n\n# calculate donation rates\ndonation_rates = df_karlan.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\nplt.bar(labels, donation_rates, color=['gray', 'blue'])\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate: Treatment vs Control')\nplt.ylim(0, 0.03)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n# T-test between the treatment and control groups on the binary outcome\ndf_gave = df_karlan[['treatment', 'gave']].dropna()\n\n# t-test\ngave_treat = df_gave[df_gave['treatment'] == 1]['gave']\ngave_ctrl = df_gave[df_gave['treatment'] == 0]['gave']\nt_stat, p_val = stats.ttest_ind(gave_treat, gave_ctrl, equal_var=False)\n\nprint(\"T-test results:\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value:     {p_val:.4f}\\n\")\n\n# linear regression\nX = sm.add_constant(df_gave['treatment'])\ny = df_gave['gave']\nmodel_ols = sm.OLS(y, X).fit()\n\nT-test results:\n  t-statistic: 3.2095\n  p-value:     0.0013\n\n\n\n\n\n\n\n# probit regression\nprobit_model = sm.Probit(y, X).fit()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\nAnalysis for Experimental Results:\nA t-test on the binary outcome showed that people in the treatment group were more likely to donate than those in the control group, and this difference was statistically significant (p-value = 0.0013). A simple linear regression gave the same result: the treatment group had a higher donation rate.\nThese results match the findings in Table 2A of the paper, showing that just being assigned to the treatment group increased the chance of giving.\nAlso, regarding the probit regression to model whether someone donated or not, the results consistent with Table 3, Column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy import stats\n\ndf_match = df_karlan[df_karlan['treatment'] == 1].copy()\n\ndf_match['ratio1'] = (df_match['ratio'] == 1).astype(int)\ndf_match['ratio2'] = (df_match['ratio'] == 2).astype(int)\ndf_match['ratio3'] = (df_match['ratio'] == 3).astype(int)\n\ngave_1to1 = df_match[df_match['ratio1'] == 1]['gave']\ngave_2to1 = df_match[df_match['ratio2'] == 1]['gave']\ngave_3to1 = df_match[df_match['ratio3'] == 1]['gave']\n\n\n# run t-tests\nttest_2_vs_1 = stats.ttest_ind(gave_2to1, gave_1to1, equal_var=False)\nttest_3_vs_2 = stats.ttest_ind(gave_3to1, gave_2to1, equal_var=False)\n\n# calculate response rates\nrate_1to1 = gave_1to1.mean()\nrate_2to1 = gave_2to1.mean()\nrate_3to1 = gave_3to1.mean()\n\nprint(\"T-test: 2:1 vs 1:1\")\nprint(f\"  Rate (1:1): {rate_1to1:.5f}\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Difference: {rate_2to1 - rate_1to1:.5f}\")\nprint(f\"  p-value:    {ttest_2_vs_1.pvalue:.5f}\\n\")\n\nprint(\"T-test: 3:1 vs 2:1\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Rate (3:1): {rate_3to1:.5f}\")\nprint(f\"  Difference: {rate_3to1 - rate_2to1:.5f}\")\nprint(f\"  p-value:    {ttest_3_vs_2.pvalue:.5f}\")\n\nT-test: 2:1 vs 1:1\n  Rate (1:1): 0.02075\n  Rate (2:1): 0.02263\n  Difference: 0.00188\n  p-value:    0.33453\n\nT-test: 3:1 vs 2:1\n  Rate (2:1): 0.02263\n  Rate (3:1): 0.02273\n  Difference: 0.00010\n  p-value:    0.96003\n\n\nAnalysis for A:\nThe p-values for both comparisons (p = 0.33 for 2:1 vs 1:1, p = 0.96 for 3:1 vs 2:1) show that these differences are not statistically significant.\nThis supports the authors’ comment on page 8 that “figures suggest” higher match ratios do not lead to significantly higher response rates.\n\n\n\n\nX = df_match[['ratio1', 'ratio2', 'ratio3']]\ny = df_match['gave']\nmodel_ratios = sm.OLS(y, X).fit()\n\nCoefficient p-value\nratio1 0.02075 0.0\nratio2 0.02263 0.0\nratio3 0.02273 0.0\nAnalysis for B:\nIt indicates that the average donation rate for each group and show that all three are statistically significant.\n\n\n\n\n# directly from data\nrate_diff_2_vs_1_data = rate_2to1 - rate_1to1\nrate_diff_3_vs_2_data = rate_3to1 - rate_2to1\n\n# from regression coefficients\ncoef_diff_2_vs_1 = model_ratios.params['ratio2'] - model_ratios.params['ratio1']\ncoef_diff_3_vs_2 = model_ratios.params['ratio3'] - model_ratios.params['ratio2']\n\nprint(\"Response Rate Differences (Direct from Data):\")\nprint(f\"  2:1 - 1:1 = {rate_diff_2_vs_1_data:.5f}\")\nprint(f\"  3:1 - 2:1 = {rate_diff_3_vs_2_data:.5f}\\n\")\n\nprint(\"Response Rate Differences (From Regression Coefficients):\")\nprint(f\"  2:1 - 1:1 = {coef_diff_2_vs_1:.5f}\")\nprint(f\"  3:1 - 2:1 = {coef_diff_3_vs_2:.5f}\")\n\nResponse Rate Differences (Direct from Data):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\nResponse Rate Differences (From Regression Coefficients):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\n\nAnalysis for C:\nThe response rate increased by 0.00188 from the 1:1 to the 2:1 match ratio, and by 0.00010 from the 2:1 to the 3:1 ratio. These results were identical when using regression coefficients. The differences are minimal, indicating that larger match ratios do not meaningfully increase the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nA:\n\ndf_amount = df_karlan[['treatment', 'amount']].dropna()\n\n# run a t-test on donation amount between treatment and control\namount_treat = df_amount[df_amount['treatment'] == 1]['amount']\namount_ctrl = df_amount[df_amount['treatment'] == 0]['amount']\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\n\nX = sm.add_constant(df_amount['treatment'])\ny = df_amount['amount']\nmodel_amount = sm.OLS(y, X).fit()\n\nreg_coef = model_amount.params['treatment']\nreg_pval = model_amount.pvalues['treatment']\nmean_treat = amount_treat.mean()\nmean_ctrl = amount_ctrl.mean()\nmean_diff = mean_treat - mean_ctrl\n\n\n{\n    \"T-test p-value\": round(p_val, 5),\n    \"Treatment group mean\": round(mean_treat, 2),\n    \"Control group mean\": round(mean_ctrl, 2),\n    \"Mean difference\": round(mean_diff, 2),\n    \"Regression coefficient\": round(reg_coef, 2),\n    \"Regression p-value\": round(reg_pval, 5)\n}\n\n{'T-test p-value': 0.05509,\n 'Treatment group mean': 0.97,\n 'Control group mean': 0.81,\n 'Mean difference': 0.15,\n 'Regression coefficient': 0.15,\n 'Regression p-value': 0.06282}\n\n\nAnalysis for A:\nT-test and linear regression both show that the average donation amount was $0.15 higher in the treatment group than in the control group ($0.97 vs $0.81).\nThe difference is marginally statistically significant (t-test p = 0.055, regression p = 0.063), suggesting that the treatment may have increased donation amounts slightly.\n\n\n\n\ndf_donors = df_karlan[(df_karlan['amount'] &gt; 0)][['treatment', 'amount']]\n\n# run regression: amount ~ treatment (conditional on donating)\nX_donors = sm.add_constant(df_donors['treatment'])\ny_donors = df_donors['amount']\nmodel_donors = sm.OLS(y_donors, X_donors).fit()\n\nreg_coef_donors = model_donors.params['treatment']\nreg_pval_donors = model_donors.pvalues['treatment']\nmean_treat_donors = df_donors[df_donors['treatment'] == 1]['amount'].mean()\nmean_ctrl_donors = df_donors[df_donors['treatment'] == 0]['amount'].mean()\nmean_diff_donors = mean_treat_donors - mean_ctrl_donors\n\n{\n    \"Treatment group mean (donors only)\": round(mean_treat_donors, 2),\n    \"Control group mean (donors only)\": round(mean_ctrl_donors, 2),\n    \"Mean difference\": round(mean_diff_donors, 2),\n    \"Regression coefficient\": round(reg_coef_donors, 2),\n    \"Regression p-value\": round(reg_pval_donors, 5)\n}\n\n{'Treatment group mean (donors only)': 43.87,\n 'Control group mean (donors only)': 45.54,\n 'Mean difference': -1.67,\n 'Regression coefficient': -1.67,\n 'Regression p-value': 0.56148}\n\n\nAnalysis for B:\nWhen restricting the analysis to only those who donated, the average donation was actually $1.67 lower in the treatment group compared to the control group ($43.87 vs $45.54). The regression confirms this difference (coefficient = -1.67), but the effect is not statistically significant (p = 0.561).\nThis suggests that, conditional on donating, the presence of a matching grant did not lead to larger donation amounts. While the treatment was randomly assigned, this analysis is not causal because it’s conditional on post-treatment behavior (donating).\n\nimport matplotlib.pyplot as plt\n\n# create subsets for donors in treatment and control\ndonors_treat = df_karlan[(df_karlan['treatment'] == 1) & (df_karlan['amount'] &gt; 0)]['amount']\ndonors_ctrl = df_karlan[(df_karlan['treatment'] == 0) & (df_karlan['amount'] &gt; 0)]['amount']\n\n\n# plot for treatment group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_treat, bins=30, color='skyblue', edgecolor='black')\nplt.axvline(donors_treat.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# plot for control group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_ctrl, bins=30, color='lightgreen', edgecolor='black')\nplt.axvline(donors_ctrl.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/project3/hw1_questions.html#simulation-experiment",
    "href": "blog/project3/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# simulate 100,000 draws from control (p = 0.018) and treatment (p = 0.022)\nn_draws = 100_000\ncontrol_draws = np.random.binomial(1, 0.018, size=n_draws)\ntreatment_draws = np.random.binomial(1, 0.022, size=n_draws)\n\ndiffs = treatment_draws - control_draws\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_draws + 1)\n\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Avg. Difference')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Differences')\nplt.title('Cumulative average of differences')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis: The cumulative average steadily approaches the true difference of 0.004, confirming the Law of Large Numbers.\n\n\nCentral Limit Theorem\n\ndef simulate_clt_differences(sample_size, n_simulations=1000, p_control=0.018, p_treat=0.022):\n    differences = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, size=sample_size)\n        treatment_sample = np.random.binomial(1, p_treat, size=sample_size)\n        diff = treatment_sample.mean() - control_sample.mean()\n        differences.append(diff)\n    return differences\n\nsample_sizes = [50, 200, 500, 1000]\n\nfor size in sample_sizes:\n    diffs = simulate_clt_differences(size)\n    plt.figure(figsize=(6, 4))\n    plt.hist(diffs, bins=30, color='lightgray', edgecolor='black')\n    plt.axvline(0, color='red', linestyle='--', label='Zero')\n    plt.axvline(0.004, color='blue', linestyle='--', label='True Diff (0.004)')\n    plt.title(f'Sample Size = {size}')\n    plt.xlabel('Avg. Difference (Treat - Control)')\n    plt.ylabel('Frequency')\n    plt.xlim(-0.06, 0.06) \n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis: As the sample size increases from 50 to 1000, the distribution of average differences becomes narrower and more centered around the true value of 0.004. In the smaller sample (n=50), the distribution is wider and zero is relatively close to the center. But as the sample size grows, zero moves further into the tail of the distribution."
  },
  {
    "objectID": "blog/project3/index.html",
    "href": "blog/project3/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including delve into the research areas of:\n\nBalance Test\nExperimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution)\nSimulation Experiment (Central Limit Theorem)"
  },
  {
    "objectID": "blog/project3/index.html#introduction",
    "href": "blog/project3/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to analyze and replicate their results, including delve into the research areas of:\n\nBalance Test\nExperimental Results (Charitable Contribution Made, Differences between Match Rates, Size of Charitable Contribution)\nSimulation Experiment (Central Limit Theorem)"
  },
  {
    "objectID": "blog/project3/index.html#data",
    "href": "blog/project3/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\n\nCode\nimport pandas as pd\n\ndata_path = \"karlan_list_2007.dta\"\ndf_karlan = pd.read_stata(data_path)\n\n\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy import stats\n\nbalance_vars = ['mrm2', 'hpa', 'freq']\ndf_clean = df_karlan[['treatment'] + balance_vars].dropna()\n\n# t-test using class slide formula\nprint(\"t-test results based on class slide formula:\")\nfor var in balance_vars:\n    group_treat = df_clean[df_clean['treatment'] == 1][var]\n    group_ctrl = df_clean[df_clean['treatment'] == 0][var]\n\n    x_t = group_treat.mean()\n    x_c = group_ctrl.mean()\n    s_t = group_treat.std(ddof=1)\n    s_c = group_ctrl.std(ddof=1)\n    n_t = group_treat.shape[0]\n    n_c = group_ctrl.shape[0]\n\n    t_manual = (x_t - x_c) / np.sqrt((s_t**2 / n_t) + (s_c**2 / n_c))\n\n    print(f\"{var}:\")\n    print(f\"  Mean (Treatment): {x_t:.3f}\")\n    print(f\"  Mean (Control):   {x_c:.3f}\")\n    print(f\"  Manual t-stat:    {t_manual:.4f}\\n\")\n\nt-test results based on class slide formula:\nmrm2:\n  Mean (Treatment): 13.012\n  Mean (Control):   12.998\n  Manual t-stat:    0.1195\n\nhpa:\n  Mean (Treatment): 59.599\n  Mean (Control):   58.960\n  Manual t-stat:    0.9731\n\nfreq:\n  Mean (Treatment): 8.036\n  Mean (Control):   8.047\n  Manual t-stat:    -0.1086\n\n\n\n\n# linear regression comparison\nprint(\"Linear regression results:\")\nfor var in balance_vars:\n    y = df_clean[var]\n    X = sm.add_constant(df_clean['treatment'])  # Adds intercept term\n    model = sm.OLS(y, X).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n\n    print(f\"{var} ~ treatment:\")\n    print(f\"  Coefficient: {coef:.4f}\")\n    print(f\"  p-value:     {pval:.4f}\\n\")\n\nLinear regression results:\nmrm2 ~ treatment:\n  Coefficient: 0.0137\n  p-value:     0.9049\n\nhpa ~ treatment:\n  Coefficient: 0.6389\n  p-value:     0.3438\n\nfreq ~ treatment:\n  Coefficient: -0.0117\n  p-value:     0.9135\n\n\n\nAnalysis for Balance Test:\nIn order to test whether the randomization successfully balanced key pre-treatment variables, I conducted both manual t-tests (using the class slide formula) and linear regressions comparing treatment and control groups on mrm2, hpa, and freq.\nIn these cases, the t-statistics were small and p-values were above 0.05, suggesting that there’s no statistically significant differences between the groups. This confirms that randomization was successful.\nThese results aligns with Table 1 in paper, which further confirms that the treatment and control groups were balanced on observable characteristics before the intervention."
  },
  {
    "objectID": "blog/project3/index.html#experimental-results",
    "href": "blog/project3/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n# Barplot with two bars for treatment and control\nimport matplotlib.pyplot as plt\n\n# calculate donation rates\ndonation_rates = df_karlan.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\nplt.bar(labels, donation_rates, color=['gray', 'blue'])\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate: Treatment vs Control')\nplt.ylim(0, 0.03)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n# T-test between the treatment and control groups on the binary outcome\ndf_gave = df_karlan[['treatment', 'gave']].dropna()\n\n# t-test\ngave_treat = df_gave[df_gave['treatment'] == 1]['gave']\ngave_ctrl = df_gave[df_gave['treatment'] == 0]['gave']\nt_stat, p_val = stats.ttest_ind(gave_treat, gave_ctrl, equal_var=False)\n\nprint(\"T-test results:\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value:     {p_val:.4f}\\n\")\n\n# linear regression\nX = sm.add_constant(df_gave['treatment'])\ny = df_gave['gave']\nmodel_ols = sm.OLS(y, X).fit()\n\nT-test results:\n  t-statistic: 3.2095\n  p-value:     0.0013\n\n\n\n\n\n\n\n# probit regression\nprobit_model = sm.Probit(y, X).fit()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\nAnalysis for Charitable Contribution Made:\nA t-test on the binary outcome showed that people in the treatment group were more likely to donate than those in the control group, and this difference was statistically significant (p-value = 0.0013). A simple linear regression gave the same result: the treatment group had a higher donation rate.\nThese results match the findings in Table 2A of the paper, showing that just being assigned to the treatment group increased the chance of giving.\nAlso, regarding the probit regression to model whether someone donated or not, the results consistent with Table 3, Column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy import stats\n\ndf_match = df_karlan[df_karlan['treatment'] == 1].copy()\n\ndf_match['ratio1'] = (df_match['ratio'] == 1).astype(int)\ndf_match['ratio2'] = (df_match['ratio'] == 2).astype(int)\ndf_match['ratio3'] = (df_match['ratio'] == 3).astype(int)\n\ngave_1to1 = df_match[df_match['ratio1'] == 1]['gave']\ngave_2to1 = df_match[df_match['ratio2'] == 1]['gave']\ngave_3to1 = df_match[df_match['ratio3'] == 1]['gave']\n\n\n# run t-tests\nttest_2_vs_1 = stats.ttest_ind(gave_2to1, gave_1to1, equal_var=False)\nttest_3_vs_2 = stats.ttest_ind(gave_3to1, gave_2to1, equal_var=False)\n\n# calculate response rates\nrate_1to1 = gave_1to1.mean()\nrate_2to1 = gave_2to1.mean()\nrate_3to1 = gave_3to1.mean()\n\nprint(\"T-test: 2:1 vs 1:1\")\nprint(f\"  Rate (1:1): {rate_1to1:.5f}\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Difference: {rate_2to1 - rate_1to1:.5f}\")\nprint(f\"  p-value:    {ttest_2_vs_1.pvalue:.5f}\\n\")\n\nprint(\"T-test: 3:1 vs 2:1\")\nprint(f\"  Rate (2:1): {rate_2to1:.5f}\")\nprint(f\"  Rate (3:1): {rate_3to1:.5f}\")\nprint(f\"  Difference: {rate_3to1 - rate_2to1:.5f}\")\nprint(f\"  p-value:    {ttest_3_vs_2.pvalue:.5f}\")\n\nT-test: 2:1 vs 1:1\n  Rate (1:1): 0.02075\n  Rate (2:1): 0.02263\n  Difference: 0.00188\n  p-value:    0.33453\n\nT-test: 3:1 vs 2:1\n  Rate (2:1): 0.02263\n  Rate (3:1): 0.02273\n  Difference: 0.00010\n  p-value:    0.96003\n\n\nAnalysis for A:\nThe p-values for both comparisons (p = 0.33 for 2:1 vs 1:1, p = 0.96 for 3:1 vs 2:1) show that these differences are not statistically significant.\nThis supports the authors’ comment on page 8 that “figures suggest” higher match ratios do not lead to significantly higher response rates.\n\n\n\n\nX = df_match[['ratio1', 'ratio2', 'ratio3']]\ny = df_match['gave']\nmodel_ratios = sm.OLS(y, X).fit()\n\nCoefficient p-value\nratio1 0.02075 0.0\nratio2 0.02263 0.0\nratio3 0.02273 0.0\nAnalysis for B:\nIt indicates that the average donation rate for each group and show that all three are statistically significant.\n\n\n\n\n# directly from data\nrate_diff_2_vs_1_data = rate_2to1 - rate_1to1\nrate_diff_3_vs_2_data = rate_3to1 - rate_2to1\n\n# from regression coefficients\ncoef_diff_2_vs_1 = model_ratios.params['ratio2'] - model_ratios.params['ratio1']\ncoef_diff_3_vs_2 = model_ratios.params['ratio3'] - model_ratios.params['ratio2']\n\nprint(\"Response Rate Differences (Direct from Data):\")\nprint(f\"  2:1 - 1:1 = {rate_diff_2_vs_1_data:.5f}\")\nprint(f\"  3:1 - 2:1 = {rate_diff_3_vs_2_data:.5f}\\n\")\n\nprint(\"Response Rate Differences (From Regression Coefficients):\")\nprint(f\"  2:1 - 1:1 = {coef_diff_2_vs_1:.5f}\")\nprint(f\"  3:1 - 2:1 = {coef_diff_3_vs_2:.5f}\")\n\nResponse Rate Differences (Direct from Data):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\nResponse Rate Differences (From Regression Coefficients):\n  2:1 - 1:1 = 0.00188\n  3:1 - 2:1 = 0.00010\n\n\nAnalysis for C:\nThe response rate increased by 0.00188 from the 1:1 to the 2:1 match ratio, and by 0.00010 from the 2:1 to the 3:1 ratio. These results were identical when using regression coefficients. The differences are minimal, indicating that larger match ratios do not meaningfully increase the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n\n\n\ndf_amount = df_karlan[['treatment', 'amount']].dropna()\n\n# run a t-test on donation amount between treatment and control\namount_treat = df_amount[df_amount['treatment'] == 1]['amount']\namount_ctrl = df_amount[df_amount['treatment'] == 0]['amount']\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\n\nX = sm.add_constant(df_amount['treatment'])\ny = df_amount['amount']\nmodel_amount = sm.OLS(y, X).fit()\n\nreg_coef = model_amount.params['treatment']\nreg_pval = model_amount.pvalues['treatment']\nmean_treat = amount_treat.mean()\nmean_ctrl = amount_ctrl.mean()\nmean_diff = mean_treat - mean_ctrl\n\n\n{\n    \"T-test p-value\": round(p_val, 5),\n    \"Treatment group mean\": round(mean_treat, 2),\n    \"Control group mean\": round(mean_ctrl, 2),\n    \"Mean difference\": round(mean_diff, 2),\n    \"Regression coefficient\": round(reg_coef, 2),\n    \"Regression p-value\": round(reg_pval, 5)\n}\n\n{'T-test p-value': 0.05509,\n 'Treatment group mean': 0.97,\n 'Control group mean': 0.81,\n 'Mean difference': 0.15,\n 'Regression coefficient': 0.15,\n 'Regression p-value': 0.06282}\n\n\nAnalysis for A:\nT-test and linear regression both show that the average donation amount was $0.15 higher in the treatment group than in the control group ($0.97 vs $0.81).\nThe difference is marginally statistically significant (t-test p = 0.055, regression p = 0.063), suggesting that the treatment may have increased donation amounts slightly.\n\n\n\n\ndf_donors = df_karlan[(df_karlan['amount'] &gt; 0)][['treatment', 'amount']]\n\n# run regression: amount ~ treatment (conditional on donating)\nX_donors = sm.add_constant(df_donors['treatment'])\ny_donors = df_donors['amount']\nmodel_donors = sm.OLS(y_donors, X_donors).fit()\n\nreg_coef_donors = model_donors.params['treatment']\nreg_pval_donors = model_donors.pvalues['treatment']\nmean_treat_donors = df_donors[df_donors['treatment'] == 1]['amount'].mean()\nmean_ctrl_donors = df_donors[df_donors['treatment'] == 0]['amount'].mean()\nmean_diff_donors = mean_treat_donors - mean_ctrl_donors\n\n{\n    \"Treatment group mean (donors only)\": round(mean_treat_donors, 2),\n    \"Control group mean (donors only)\": round(mean_ctrl_donors, 2),\n    \"Mean difference\": round(mean_diff_donors, 2),\n    \"Regression coefficient\": round(reg_coef_donors, 2),\n    \"Regression p-value\": round(reg_pval_donors, 5)\n}\n\n{'Treatment group mean (donors only)': 43.87,\n 'Control group mean (donors only)': 45.54,\n 'Mean difference': -1.67,\n 'Regression coefficient': -1.67,\n 'Regression p-value': 0.56148}\n\n\nAnalysis for B:\nWhen restricting the analysis to only those who donated, the average donation was actually $1.67 lower in the treatment group compared to the control group ($43.87 vs $45.54). The regression confirms this difference (coefficient = -1.67), but the effect is not statistically significant (p = 0.561).\nThis suggests that, conditional on donating, the presence of a matching grant did not lead to larger donation amounts. While the treatment was randomly assigned, this analysis is not causal because it’s conditional on post-treatment behavior (donating).\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# create subsets for donors in treatment and control\ndonors_treat = df_karlan[(df_karlan['treatment'] == 1) & (df_karlan['amount'] &gt; 0)]['amount']\ndonors_ctrl = df_karlan[(df_karlan['treatment'] == 0) & (df_karlan['amount'] &gt; 0)]['amount']\n\n\n# plot for treatment group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_treat, bins=30, color='skyblue', edgecolor='black')\nplt.axvline(donors_treat.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# plot for control group \nplt.figure(figsize=(6, 4))\nplt.hist(donors_ctrl, bins=30, color='lightgreen', edgecolor='black')\nplt.axvline(donors_ctrl.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/project3/index.html#simulation-experiment",
    "href": "blog/project3/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# simulate 100,000 draws from control (p = 0.018) and treatment (p = 0.022)\nn_draws = 100_000\ncontrol_draws = np.random.binomial(1, 0.018, size=n_draws)\ntreatment_draws = np.random.binomial(1, 0.022, size=n_draws)\n\ndiffs = treatment_draws - control_draws\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_draws + 1)\n\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Avg. Difference')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Differences')\nplt.title('Cumulative average of differences')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis: The cumulative average steadily approaches the true difference of 0.004, confirming the Law of Large Numbers.\n\n\nCentral Limit Theorem\n\ndef simulate_clt_differences(sample_size, n_simulations=1000, p_control=0.018, p_treat=0.022):\n    differences = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, size=sample_size)\n        treatment_sample = np.random.binomial(1, p_treat, size=sample_size)\n        diff = treatment_sample.mean() - control_sample.mean()\n        differences.append(diff)\n    return differences\n\nsample_sizes = [50, 200, 500, 1000]\n\nfor size in sample_sizes:\n    diffs = simulate_clt_differences(size)\n    plt.figure(figsize=(6, 4))\n    plt.hist(diffs, bins=30, color='lightgray', edgecolor='black')\n    plt.axvline(0, color='red', linestyle='--', label='Zero')\n    plt.axvline(0.004, color='blue', linestyle='--', label='True Diff (0.004)')\n    plt.title(f'Sample Size = {size}')\n    plt.xlabel('Avg. Difference (Treat - Control)')\n    plt.ylabel('Frequency')\n    plt.xlim(-0.06, 0.06) \n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis: As the sample size increases from 50 to 1000, the distribution of average differences becomes narrower and more centered around the true value of 0.004. In the smaller sample (n=50), the distribution is wider and zero is relatively close to the center. But as the sample size grows, zero moves further into the tail of the distribution."
  },
  {
    "objectID": "blog/project4/hw2_questions.html",
    "href": "blog/project4/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nA.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import optimize\nfrom scipy.special import gammaln\n\ndata_path = 'blueprinty.csv'\ndf_blueprinty = pd.read_csv(data_path)\n\ndf_blueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\nAbove is the overview of the blueprinty dataset.\nB.\n\nimport matplotlib.pyplot as plt\n\ncustomers = df_blueprinty[df_blueprinty['iscustomer'] == 1]\nnon_customers = df_blueprinty[df_blueprinty['iscustomer'] == 0]\n\nmean_customers = customers['patents'].mean()\nmean_non_customers = non_customers['patents'].mean()\n\nprint(mean_non_customers, mean_customers)\n\n3.4730127576054954 4.133056133056133\n\n\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 5))\nplt.hist(non_customers['patents'], bins=20, alpha=0.6, label='Non-Customers')\nplt.hist(customers['patents'], bins=20, alpha=0.6, label='Customers')\nplt.axvline(mean_non_customers, color='blue', linestyle='dashed', linewidth=2)\nplt.axvline(mean_customers, color='orange', linestyle='dashed', linewidth=2)\nplt.title('Histogram of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis for B:\n\nMean for patents (non-customers): ≈ 3.47\nMean for patents (customers): ≈ 4.13\n\nRegarding the means of number of patents by customer status, it shows that firms that use Blueprinty’s software have a higher average number of awarded patents than those that don’t. Also, the histogram shows a right shift for customers, indicating a general higher counts of patent. These findings potentially indicates the positive association between usage of Blueprinty’s software and patent success.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nC.\n\nregion_counts = df_blueprinty.groupby(['iscustomer', 'region']).size().unstack(fill_value=0)\nage_summary = df_blueprinty.groupby('iscustomer')['age'].describe()\n\nregion_counts\n\n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n0\n187\n273\n158\n156\n245\n\n\n1\n37\n328\n29\n35\n52\n\n\n\n\n\n\n\n\nage_summary\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1019.0\n26.101570\n6.945426\n9.0\n21.0\n25.5\n31.25\n47.5\n\n\n1\n481.0\n26.900208\n7.814678\n10.0\n20.5\n26.5\n32.50\n49.0\n\n\n\n\n\n\n\nAnalysis for C:\nComparing regions and ages by customer status, we observed that:\n\nRegion:\n\nNon-customers are more evenly spread across regions.\nNortheast region has a significantly higher number of Blueprinty software customers compared to other regions.\n\nAge:\n\nBlueprinty software Customers have a slightly higher average age (26.9 years) compared to non-customers (26.1 years).\nBlueprinty software Customers’ age are slightly older, with a wider spread in age distribution by higher standard deviation.\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nA.\nNote that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\). we can have the likelihood function for \\(Y \\sim \\text{Poisson}(\\lambda)\\) is \\(L(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\\).\nB.\nCoding for log-likelihood function for the Poisson Model (This is a function of lambda and Y):\n\ndef poisson_loglikelihood(lambda_, Y):\n    Y = np.array(Y)\n    log_likelihood = np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n    return log_likelihood\n\nC.\n\nY = df_blueprinty[\"patents\"].values  # observed patent counts\n\nlambda_vals = np.linspace(0.1, 10, 200)\nlog_likelihoods = [poisson_loglikelihood(lam, Y) for lam in lambda_vals]\n\n# Plot the log-likelihood curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods)\nplt.xlabel(\"λ (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood as a Function of λ\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAbove is the plot of the Poisson log-likelihood as a function of λ based on the observed patent counts. The curve peaks around λ ≈ 3.5 to 4, which indicates that the Maximum Likelihood Estimator (MLE) for λ.\nD.\nAfter taking the first derivative of log-likelihood, set it equal to zero and solve for lambda, the Maximum Likelihood Estimator for \\(\\lambda\\) is \\(\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\\). It indicates that the mean of a Poisson distribution is lambda.\nE.\n\nresult = optimize.minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10),\n    method='bounded'\n)\n\nlambda_mle = result.x\nprint(\"λ_MLE from optimization:\", lambda_mle)\n\nλ_MLE from optimization: 3.6846662261327716\n\n\nThen, we found the MLE with a value of 3.6846662261327716 by optimizing the likelihood function.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nThen, we’ll update log-likelihood function with an additional argument to take in a covariate matrix X.\nA.\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    Y = np.array(Y)\n    X = np.array(X)\n\n    lambda_ = np.exp(X @ beta)  \n    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n\nB.\n\nimport numpy as np\ndf_blueprinty['age_squared'] = df_blueprinty['age'] ** 2\nregion_dummies = pd.get_dummies(df_blueprinty['region'], drop_first=True)\n\nX = pd.concat([\n    pd.Series(1.0, index=df_blueprinty.index, name='intercept'),  \n    df_blueprinty[['age', 'age_squared', 'iscustomer']],\n    region_dummies\n], axis=1).astype(float)\n\nY = df_blueprinty['patents'].values\nX_matrix = X.values.astype(float)\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    lin_pred = X @ beta\n    lambda_ = np.exp(np.clip(lin_pred, -100, 100))  \n    return np.sum(-lambda_ + Y * np.log(np.clip(lambda_, 1e-10, None)) - gammaln(Y + 1))\n  \ndef neg_loglik(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\ninitial_beta = np.zeros(X.shape[1])\nresult = optimize.minimize(\n    fun=neg_loglik,\n    x0=initial_beta,\n    args=(Y, X_matrix),\n    method='BFGS'\n)\n\nbeta_mle = result.x\nhessian_inv = result.hess_inv  \nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\nsummary = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': standard_errors\n}, index=X.columns)\n\nsummary\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.509992\n0.074991\n\n\nage\n0.148706\n0.004109\n\n\nage_squared\n-0.002972\n0.000101\n\n\niscustomer\n0.207609\n0.028164\n\n\nNortheast\n0.029155\n0.059189\n\n\nNorthwest\n-0.017578\n0.059060\n\n\nSouth\n0.056565\n0.066770\n\n\nSouthwest\n0.050567\n0.074074\n\n\n\n\n\n\n\nThrough finding the MLE vector and the Hessian of the Poisson model with covariates, above is the table of coefficients and standard errors for using the Hessain to find standard errors of the beta parameter estimates.\nC.\n\nimport statsmodels.api as sm\n\nglm_poisson = sm.GLM(Y, X, family=sm.families.Poisson())\nglm_result = glm_poisson.fit()\n\ncoeff_table = glm_result.summary2().tables[1]\nprint(coeff_table)\n\n                Coef.  Std.Err.          z         P&gt;|z|    [0.025    0.975]\nintercept   -0.508920  0.183179  -2.778269  5.464935e-03 -0.867944 -0.149896\nage          0.148619  0.013869  10.716250  8.539597e-27  0.121438  0.175801\nage_squared -0.002970  0.000258 -11.513237  1.131496e-30 -0.003476 -0.002465\niscustomer   0.207591  0.030895   6.719179  1.827509e-11  0.147037  0.268144\nNortheast    0.029170  0.043625   0.668647  5.037205e-01 -0.056334  0.114674\nNorthwest   -0.017575  0.053781  -0.326782  7.438327e-01 -0.122983  0.087833\nSouth        0.056561  0.052662   1.074036  2.828066e-01 -0.046655  0.159778\nSouthwest    0.050576  0.047198   1.071568  2.839141e-01 -0.041931  0.143083\n\n\nAnalysis for C:\nBy checking the poisson regression model results using sm.GLM() function, we find that age, age_squared, and customer status are statistically significant different from patent counts (p-value &lt; 0.05). As firm age increases, there are expected patent counts increase. Also, customers of Blueprinty tend to have significantly higher expected patent counts than non-customers. Additionally, regions are not satistically significant different from patent counts (p-value &gt; 0.05) when other variables are controlled.\nD.\n\nX_0 = X.copy()\nX_1 = X.copy()\n\nX_0['iscustomer'] = 0\nX_1['iscustomer'] = 1\n\ny_pred_0 = glm_result.predict(X_0)\ny_pred_1 = glm_result.predict(X_1)\n\neffect = y_pred_1 - y_pred_0\navg_effect = np.mean(effect)\n\nprint(\"Average predicted increase in patents from using Blueprinty software:\", avg_effect)\n\nAverage predicted increase in patents from using Blueprinty software: 0.7927680710452972\n\n\nAnalysis for D:\nBased on the poisson regression model, we can conclude that the usage of Blueprinty software is associated with an average increase of approximately 0.79 patents per firm."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "href": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nA.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import optimize\nfrom scipy.special import gammaln\n\ndata_path = 'blueprinty.csv'\ndf_blueprinty = pd.read_csv(data_path)\n\ndf_blueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\nAbove is the overview of the blueprinty dataset.\nB.\n\nimport matplotlib.pyplot as plt\n\ncustomers = df_blueprinty[df_blueprinty['iscustomer'] == 1]\nnon_customers = df_blueprinty[df_blueprinty['iscustomer'] == 0]\n\nmean_customers = customers['patents'].mean()\nmean_non_customers = non_customers['patents'].mean()\n\nprint(mean_non_customers, mean_customers)\n\n3.4730127576054954 4.133056133056133\n\n\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 5))\nplt.hist(non_customers['patents'], bins=20, alpha=0.6, label='Non-Customers')\nplt.hist(customers['patents'], bins=20, alpha=0.6, label='Customers')\nplt.axvline(mean_non_customers, color='blue', linestyle='dashed', linewidth=2)\nplt.axvline(mean_customers, color='orange', linestyle='dashed', linewidth=2)\nplt.title('Histogram of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis for B:\n\nMean for patents (non-customers): ≈ 3.47\nMean for patents (customers): ≈ 4.13\n\nRegarding the means of number of patents by customer status, it shows that firms that use Blueprinty’s software have a higher average number of awarded patents than those that don’t. Also, the histogram shows a right shift for customers, indicating a general higher counts of patent. These findings potentially indicates the positive association between usage of Blueprinty’s software and patent success.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nC.\n\nregion_counts = df_blueprinty.groupby(['iscustomer', 'region']).size().unstack(fill_value=0)\nage_summary = df_blueprinty.groupby('iscustomer')['age'].describe()\n\nregion_counts\n\n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n0\n187\n273\n158\n156\n245\n\n\n1\n37\n328\n29\n35\n52\n\n\n\n\n\n\n\n\nage_summary\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1019.0\n26.101570\n6.945426\n9.0\n21.0\n25.5\n31.25\n47.5\n\n\n1\n481.0\n26.900208\n7.814678\n10.0\n20.5\n26.5\n32.50\n49.0\n\n\n\n\n\n\n\nAnalysis for C:\nComparing regions and ages by customer status, we observed that:\n\nRegion:\n\nNon-customers are more evenly spread across regions.\nNortheast region has a significantly higher number of Blueprinty software customers compared to other regions.\n\nAge:\n\nBlueprinty software Customers have a slightly higher average age (26.9 years) compared to non-customers (26.1 years).\nBlueprinty software Customers’ age are slightly older, with a wider spread in age distribution by higher standard deviation.\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nA.\nNote that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\). we can have the likelihood function for \\(Y \\sim \\text{Poisson}(\\lambda)\\) is \\(L(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\\).\nB.\nCoding for log-likelihood function for the Poisson Model (This is a function of lambda and Y):\n\ndef poisson_loglikelihood(lambda_, Y):\n    Y = np.array(Y)\n    log_likelihood = np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n    return log_likelihood\n\nC.\n\nY = df_blueprinty[\"patents\"].values  # observed patent counts\n\nlambda_vals = np.linspace(0.1, 10, 200)\nlog_likelihoods = [poisson_loglikelihood(lam, Y) for lam in lambda_vals]\n\n# Plot the log-likelihood curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods)\nplt.xlabel(\"λ (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood as a Function of λ\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAbove is the plot of the Poisson log-likelihood as a function of λ based on the observed patent counts. The curve peaks around λ ≈ 3.5 to 4, which indicates that the Maximum Likelihood Estimator (MLE) for λ.\nD.\nAfter taking the first derivative of log-likelihood, set it equal to zero and solve for lambda, the Maximum Likelihood Estimator for \\(\\lambda\\) is \\(\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\\). It indicates that the mean of a Poisson distribution is lambda.\nE.\n\nresult = optimize.minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10),\n    method='bounded'\n)\n\nlambda_mle = result.x\nprint(\"λ_MLE from optimization:\", lambda_mle)\n\nλ_MLE from optimization: 3.6846662261327716\n\n\nThen, we found the MLE with a value of 3.6846662261327716 by optimizing the likelihood function.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nThen, we’ll update log-likelihood function with an additional argument to take in a covariate matrix X.\nA.\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    Y = np.array(Y)\n    X = np.array(X)\n\n    lambda_ = np.exp(X @ beta)  \n    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n\nB.\n\nimport numpy as np\ndf_blueprinty['age_squared'] = df_blueprinty['age'] ** 2\nregion_dummies = pd.get_dummies(df_blueprinty['region'], drop_first=True)\n\nX = pd.concat([\n    pd.Series(1.0, index=df_blueprinty.index, name='intercept'),  \n    df_blueprinty[['age', 'age_squared', 'iscustomer']],\n    region_dummies\n], axis=1).astype(float)\n\nY = df_blueprinty['patents'].values\nX_matrix = X.values.astype(float)\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    lin_pred = X @ beta\n    lambda_ = np.exp(np.clip(lin_pred, -100, 100))  \n    return np.sum(-lambda_ + Y * np.log(np.clip(lambda_, 1e-10, None)) - gammaln(Y + 1))\n  \ndef neg_loglik(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\ninitial_beta = np.zeros(X.shape[1])\nresult = optimize.minimize(\n    fun=neg_loglik,\n    x0=initial_beta,\n    args=(Y, X_matrix),\n    method='BFGS'\n)\n\nbeta_mle = result.x\nhessian_inv = result.hess_inv  \nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\nsummary = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': standard_errors\n}, index=X.columns)\n\nsummary\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.509992\n0.074991\n\n\nage\n0.148706\n0.004109\n\n\nage_squared\n-0.002972\n0.000101\n\n\niscustomer\n0.207609\n0.028164\n\n\nNortheast\n0.029155\n0.059189\n\n\nNorthwest\n-0.017578\n0.059060\n\n\nSouth\n0.056565\n0.066770\n\n\nSouthwest\n0.050567\n0.074074\n\n\n\n\n\n\n\nThrough finding the MLE vector and the Hessian of the Poisson model with covariates, above is the table of coefficients and standard errors for using the Hessain to find standard errors of the beta parameter estimates.\nC.\n\nimport statsmodels.api as sm\n\nglm_poisson = sm.GLM(Y, X, family=sm.families.Poisson())\nglm_result = glm_poisson.fit()\n\ncoeff_table = glm_result.summary2().tables[1]\nprint(coeff_table)\n\n                Coef.  Std.Err.          z         P&gt;|z|    [0.025    0.975]\nintercept   -0.508920  0.183179  -2.778269  5.464935e-03 -0.867944 -0.149896\nage          0.148619  0.013869  10.716250  8.539597e-27  0.121438  0.175801\nage_squared -0.002970  0.000258 -11.513237  1.131496e-30 -0.003476 -0.002465\niscustomer   0.207591  0.030895   6.719179  1.827509e-11  0.147037  0.268144\nNortheast    0.029170  0.043625   0.668647  5.037205e-01 -0.056334  0.114674\nNorthwest   -0.017575  0.053781  -0.326782  7.438327e-01 -0.122983  0.087833\nSouth        0.056561  0.052662   1.074036  2.828066e-01 -0.046655  0.159778\nSouthwest    0.050576  0.047198   1.071568  2.839141e-01 -0.041931  0.143083\n\n\nAnalysis for C:\nBy checking the poisson regression model results using sm.GLM() function, we find that age, age_squared, and customer status are statistically significant different from patent counts (p-value &lt; 0.05). As firm age increases, there are expected patent counts increase. Also, customers of Blueprinty tend to have significantly higher expected patent counts than non-customers. Additionally, regions are not satistically significant different from patent counts (p-value &gt; 0.05) when other variables are controlled.\nD.\n\nX_0 = X.copy()\nX_1 = X.copy()\n\nX_0['iscustomer'] = 0\nX_1['iscustomer'] = 1\n\ny_pred_0 = glm_result.predict(X_0)\ny_pred_1 = glm_result.predict(X_1)\n\neffect = y_pred_1 - y_pred_0\navg_effect = np.mean(effect)\n\nprint(\"Average predicted increase in patents from using Blueprinty software:\", avg_effect)\n\nAverage predicted increase in patents from using Blueprinty software: 0.7927680710452972\n\n\nAnalysis for D:\nBased on the poisson regression model, we can conclude that the usage of Blueprinty software is associated with an average increase of approximately 0.79 patents per firm."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#airbnb-case-study",
    "href": "blog/project4/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\nAssume the number of reviews is a good proxy for the number of bookings, then we performed some EDA for Airbnb data:\n\nfile_path_airbnb = \"airbnb.csv\" \ndf_airbnb = pd.read_csv(file_path_airbnb)\n\nsummary_info = df_airbnb.info()\nmissing_values = df_airbnb.isnull().sum()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\n\n\n\ndf_airbnb.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\nmissing_values\n\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\nRegarding the exploratory data analysis of the data, it shows that the relevant variables including host_since, bathrooms, review_scores_cleanliness, review_scores_location, review_scores_value have missing values within it. Then, we performed the handle of dropping these relevant variables’ missing values and built a poisson regression model for the number of bookings as proxied by the number of reviews.\n\nrelevant_vars = [\n    'number_of_reviews', 'room_type', 'bathrooms', 'bedrooms', 'price',\n    'review_scores_cleanliness', 'review_scores_location', 'review_scores_value',\n    'instant_bookable'\n]\ndf_clean = df_airbnb[relevant_vars].dropna()\n\n\ndf_clean = pd.get_dummies(df_clean, columns=['room_type', 'instant_bookable'], drop_first=True)\n\n\nX = df_clean.drop(columns=['number_of_reviews'])\nX = sm.add_constant(X)  # Add intercept\nY = df_clean['number_of_reviews']\n\nX = X.astype(float)\nY = Y.astype(float)\n\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()\n\ncoef_table = poisson_model.summary2().tables[1]\ncoef_table\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\n\n\nconst\n3.572486\n0.016005\n223.214538\n0.000000e+00\n3.541117\n3.603855\n\n\nbathrooms\n-0.123999\n0.003747\n-33.090794\n4.031530e-240\n-0.131344\n-0.116655\n\n\nbedrooms\n0.074941\n0.001988\n37.697741\n0.000000e+00\n0.071045\n0.078838\n\n\nprice\n-0.000014\n0.000008\n-1.728798\n8.384521e-02\n-0.000031\n0.000002\n\n\nreview_scores_cleanliness\n0.113187\n0.001493\n75.820487\n0.000000e+00\n0.110261\n0.116113\n\n\nreview_scores_location\n-0.076795\n0.001607\n-47.795559\n0.000000e+00\n-0.079944\n-0.073646\n\n\nreview_scores_value\n-0.091529\n0.001798\n-50.902050\n0.000000e+00\n-0.095053\n-0.088005\n\n\nroom_type_Private room\n-0.014535\n0.002737\n-5.310442\n1.093597e-07\n-0.019899\n-0.009170\n\n\nroom_type_Shared room\n-0.251896\n0.008618\n-29.228586\n8.404519e-188\n-0.268787\n-0.235005\n\n\ninstant_bookable_t\n0.334397\n0.002889\n115.747697\n0.000000e+00\n0.328734\n0.340059\n\n\n\n\n\n\n\nRegarding the model coefficients, we found that:\n\nInstant Bookable and Cleanliness both have the strongest positive association with the number of reviews.\nMore Bathrooms slightly decrease the number of reviews; however, more Bedrooms increase the number of reviews.\nPrice has small, marginally insignificant effect with the number of reviews.\nHigher location scores decrease the number of reviews; meanwhile, higher value scores also decrease the number of reviews.\nPrivate rooms get few reviews than the entire home/apt; meanwhile, shared rooms get much fewer reviews than the entire home/apt."
  },
  {
    "objectID": "blog/project4/index.html",
    "href": "blog/project4/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nA.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import optimize\nfrom scipy.special import gammaln\n\ndata_path = 'blueprinty.csv'\ndf_blueprinty = pd.read_csv(data_path)\n\ndf_blueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\nAbove is the overview of the blueprinty dataset.\nB.\n\nimport matplotlib.pyplot as plt\n\ncustomers = df_blueprinty[df_blueprinty['iscustomer'] == 1]\nnon_customers = df_blueprinty[df_blueprinty['iscustomer'] == 0]\n\nmean_customers = customers['patents'].mean()\nmean_non_customers = non_customers['patents'].mean()\n\nprint(mean_non_customers, mean_customers)\n\n3.4730127576054954 4.133056133056133\n\n\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 5))\nplt.hist(non_customers['patents'], bins=20, alpha=0.6, label='Non-Customers')\nplt.hist(customers['patents'], bins=20, alpha=0.6, label='Customers')\nplt.axvline(mean_non_customers, color='blue', linestyle='dashed', linewidth=2)\nplt.axvline(mean_customers, color='orange', linestyle='dashed', linewidth=2)\nplt.title('Histogram of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis for B:\n\nMean for patents (non-customers): ≈ 3.47\nMean for patents (customers): ≈ 4.13\n\nRegarding the means of number of patents by customer status, it shows that firms that use Blueprinty’s software have a higher average number of awarded patents than those that don’t. Also, the histogram shows a right shift for customers, indicating a general higher counts of patent. These findings potentially indicates the positive association between usage of Blueprinty’s software and patent success.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nC.\n\nregion_counts = df_blueprinty.groupby(['iscustomer', 'region']).size().unstack(fill_value=0)\nage_summary = df_blueprinty.groupby('iscustomer')['age'].describe()\n\nregion_counts\n\n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n0\n187\n273\n158\n156\n245\n\n\n1\n37\n328\n29\n35\n52\n\n\n\n\n\n\n\n\nage_summary\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1019.0\n26.101570\n6.945426\n9.0\n21.0\n25.5\n31.25\n47.5\n\n\n1\n481.0\n26.900208\n7.814678\n10.0\n20.5\n26.5\n32.50\n49.0\n\n\n\n\n\n\n\nAnalysis for C:\nComparing regions and ages by customer status, we observed that:\n\nRegion:\n\nNon-customers are more evenly spread across regions.\nNortheast region has a significantly higher number of Blueprinty software customers compared to other regions.\n\nAge:\n\nBlueprinty software Customers have a slightly higher average age (26.9 years) compared to non-customers (26.1 years).\nBlueprinty software Customers’ age are slightly older, with a wider spread in age distribution by higher standard deviation.\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nA.\nNote that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\). we can have the likelihood function for \\(Y \\sim \\text{Poisson}(\\lambda)\\) is \\(L(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\\).\nB.\nCoding for log-likelihood function for the Poisson Model (This is a function of lambda and Y):\n\ndef poisson_loglikelihood(lambda_, Y):\n    Y = np.array(Y)\n    log_likelihood = np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n    return log_likelihood\n\nC.\n\nY = df_blueprinty[\"patents\"].values  # observed patent counts\n\nlambda_vals = np.linspace(0.1, 10, 200)\nlog_likelihoods = [poisson_loglikelihood(lam, Y) for lam in lambda_vals]\n\n# Plot the log-likelihood curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods)\nplt.xlabel(\"λ (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood as a Function of λ\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAbove is the plot of the Poisson log-likelihood as a function of λ based on the observed patent counts. The curve peaks around λ ≈ 3.5 to 4, which indicates that the Maximum Likelihood Estimator (MLE) for λ.\nD.\nAfter taking the first derivative of log-likelihood, set it equal to zero and solve for lambda, the Maximum Likelihood Estimator for \\(\\lambda\\) is \\(\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\\). It indicates that the mean of a Poisson distribution is lambda.\nE.\n\nresult = optimize.minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10),\n    method='bounded'\n)\n\nlambda_mle = result.x\nprint(\"λ_MLE from optimization:\", lambda_mle)\n\nλ_MLE from optimization: 3.6846662261327716\n\n\nThen, we found the MLE with a value of 3.6846662261327716 by optimizing the likelihood function.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nThen, we’ll update log-likelihood function with an additional argument to take in a covariate matrix X.\nA.\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    Y = np.array(Y)\n    X = np.array(X)\n\n    lambda_ = np.exp(X @ beta)  \n    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n\nB.\n\nimport numpy as np\ndf_blueprinty['age_squared'] = df_blueprinty['age'] ** 2\nregion_dummies = pd.get_dummies(df_blueprinty['region'], drop_first=True)\n\nX = pd.concat([\n    pd.Series(1.0, index=df_blueprinty.index, name='intercept'),  \n    df_blueprinty[['age', 'age_squared', 'iscustomer']],\n    region_dummies\n], axis=1).astype(float)\n\nY = df_blueprinty['patents'].values\nX_matrix = X.values.astype(float)\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    lin_pred = X @ beta\n    lambda_ = np.exp(np.clip(lin_pred, -100, 100))  \n    return np.sum(-lambda_ + Y * np.log(np.clip(lambda_, 1e-10, None)) - gammaln(Y + 1))\n  \ndef neg_loglik(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\ninitial_beta = np.zeros(X.shape[1])\nresult = optimize.minimize(\n    fun=neg_loglik,\n    x0=initial_beta,\n    args=(Y, X_matrix),\n    method='BFGS'\n)\n\nbeta_mle = result.x\nhessian_inv = result.hess_inv  \nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\nsummary = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': standard_errors\n}, index=X.columns)\n\nsummary\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.509992\n0.074991\n\n\nage\n0.148706\n0.004109\n\n\nage_squared\n-0.002972\n0.000101\n\n\niscustomer\n0.207609\n0.028164\n\n\nNortheast\n0.029155\n0.059189\n\n\nNorthwest\n-0.017578\n0.059060\n\n\nSouth\n0.056565\n0.066770\n\n\nSouthwest\n0.050567\n0.074074\n\n\n\n\n\n\n\nThrough finding the MLE vector and the Hessian of the Poisson model with covariates, above is the table of coefficients and standard errors for using the Hessain to find standard errors of the beta parameter estimates.\nC.\n\nimport statsmodels.api as sm\n\nglm_poisson = sm.GLM(Y, X, family=sm.families.Poisson())\nglm_result = glm_poisson.fit()\n\ncoeff_table = glm_result.summary2().tables[1]\nprint(coeff_table)\n\n                Coef.  Std.Err.          z         P&gt;|z|    [0.025    0.975]\nintercept   -0.508920  0.183179  -2.778269  5.464935e-03 -0.867944 -0.149896\nage          0.148619  0.013869  10.716250  8.539597e-27  0.121438  0.175801\nage_squared -0.002970  0.000258 -11.513237  1.131496e-30 -0.003476 -0.002465\niscustomer   0.207591  0.030895   6.719179  1.827509e-11  0.147037  0.268144\nNortheast    0.029170  0.043625   0.668647  5.037205e-01 -0.056334  0.114674\nNorthwest   -0.017575  0.053781  -0.326782  7.438327e-01 -0.122983  0.087833\nSouth        0.056561  0.052662   1.074036  2.828066e-01 -0.046655  0.159778\nSouthwest    0.050576  0.047198   1.071568  2.839141e-01 -0.041931  0.143083\n\n\nAnalysis for C:\nBy checking the poisson regression model results using sm.GLM() function, we find that age, age_squared, and customer status are statistically significant different from patent counts (p-value &lt; 0.05). As firm age increases, there are expected patent counts increase. Also, customers of Blueprinty tend to have significantly higher expected patent counts than non-customers. Additionally, regions are not satistically significant different from patent counts (p-value &gt; 0.05) when other variables are controlled.\nD.\n\nX_0 = X.copy()\nX_1 = X.copy()\n\nX_0['iscustomer'] = 0\nX_1['iscustomer'] = 1\n\ny_pred_0 = glm_result.predict(X_0)\ny_pred_1 = glm_result.predict(X_1)\n\neffect = y_pred_1 - y_pred_0\navg_effect = np.mean(effect)\n\nprint(\"Average predicted increase in patents from using Blueprinty software:\", avg_effect)\n\nAverage predicted increase in patents from using Blueprinty software: 0.7927680710452972\n\n\nAnalysis for D:\nBased on the poisson regression model, we can conclude that the usage of Blueprinty software is associated with an average increase of approximately 0.79 patents per firm."
  },
  {
    "objectID": "blog/project4/index.html#blueprinty-case-study",
    "href": "blog/project4/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nA.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import optimize\nfrom scipy.special import gammaln\n\ndata_path = 'blueprinty.csv'\ndf_blueprinty = pd.read_csv(data_path)\n\ndf_blueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\nAbove is the overview of the blueprinty dataset.\nB.\n\nimport matplotlib.pyplot as plt\n\ncustomers = df_blueprinty[df_blueprinty['iscustomer'] == 1]\nnon_customers = df_blueprinty[df_blueprinty['iscustomer'] == 0]\n\nmean_customers = customers['patents'].mean()\nmean_non_customers = non_customers['patents'].mean()\n\nprint(mean_non_customers, mean_customers)\n\n3.4730127576054954 4.133056133056133\n\n\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 5))\nplt.hist(non_customers['patents'], bins=20, alpha=0.6, label='Non-Customers')\nplt.hist(customers['patents'], bins=20, alpha=0.6, label='Customers')\nplt.axvline(mean_non_customers, color='blue', linestyle='dashed', linewidth=2)\nplt.axvline(mean_customers, color='orange', linestyle='dashed', linewidth=2)\nplt.title('Histogram of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAnalysis for B:\n\nMean for patents (non-customers): ≈ 3.47\nMean for patents (customers): ≈ 4.13\n\nRegarding the means of number of patents by customer status, it shows that firms that use Blueprinty’s software have a higher average number of awarded patents than those that don’t. Also, the histogram shows a right shift for customers, indicating a general higher counts of patent. These findings potentially indicates the positive association between usage of Blueprinty’s software and patent success.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nC.\n\nregion_counts = df_blueprinty.groupby(['iscustomer', 'region']).size().unstack(fill_value=0)\nage_summary = df_blueprinty.groupby('iscustomer')['age'].describe()\n\nregion_counts\n\n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n0\n187\n273\n158\n156\n245\n\n\n1\n37\n328\n29\n35\n52\n\n\n\n\n\n\n\n\nage_summary\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1019.0\n26.101570\n6.945426\n9.0\n21.0\n25.5\n31.25\n47.5\n\n\n1\n481.0\n26.900208\n7.814678\n10.0\n20.5\n26.5\n32.50\n49.0\n\n\n\n\n\n\n\nAnalysis for C:\nComparing regions and ages by customer status, we observed that:\n\nRegion:\n\nNon-customers are more evenly spread across regions.\nNortheast region has a significantly higher number of Blueprinty software customers compared to other regions.\n\nAge:\n\nBlueprinty software Customers have a slightly higher average age (26.9 years) compared to non-customers (26.1 years).\nBlueprinty software Customers’ age are slightly older, with a wider spread in age distribution by higher standard deviation.\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nA.\nNote that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\). we can have the likelihood function for \\(Y \\sim \\text{Poisson}(\\lambda)\\) is \\(L(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\\).\nB.\nCoding for log-likelihood function for the Poisson Model (This is a function of lambda and Y):\n\ndef poisson_loglikelihood(lambda_, Y):\n    Y = np.array(Y)\n    log_likelihood = np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n    return log_likelihood\n\nC.\n\nY = df_blueprinty[\"patents\"].values  # observed patent counts\n\nlambda_vals = np.linspace(0.1, 10, 200)\nlog_likelihoods = [poisson_loglikelihood(lam, Y) for lam in lambda_vals]\n\n# Plot the log-likelihood curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods)\nplt.xlabel(\"λ (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood as a Function of λ\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAbove is the plot of the Poisson log-likelihood as a function of λ based on the observed patent counts. The curve peaks around λ ≈ 3.5 to 4, which indicates that the Maximum Likelihood Estimator (MLE) for λ.\nD.\nAfter taking the first derivative of log-likelihood, set it equal to zero and solve for lambda, the Maximum Likelihood Estimator for \\(\\lambda\\) is \\(\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\\). It indicates that the mean of a Poisson distribution is lambda.\nE.\n\nresult = optimize.minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10),\n    method='bounded'\n)\n\nlambda_mle = result.x\nprint(\"λ_MLE from optimization:\", lambda_mle)\n\nλ_MLE from optimization: 3.6846662261327716\n\n\nThen, we found the MLE with a value of 3.6846662261327716 by optimizing the likelihood function.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nThen, we’ll update log-likelihood function with an additional argument to take in a covariate matrix X.\nA.\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    Y = np.array(Y)\n    X = np.array(X)\n\n    lambda_ = np.exp(X @ beta)  \n    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n\nB.\n\nimport numpy as np\ndf_blueprinty['age_squared'] = df_blueprinty['age'] ** 2\nregion_dummies = pd.get_dummies(df_blueprinty['region'], drop_first=True)\n\nX = pd.concat([\n    pd.Series(1.0, index=df_blueprinty.index, name='intercept'),  \n    df_blueprinty[['age', 'age_squared', 'iscustomer']],\n    region_dummies\n], axis=1).astype(float)\n\nY = df_blueprinty['patents'].values\nX_matrix = X.values.astype(float)\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta)\n    lin_pred = X @ beta\n    lambda_ = np.exp(np.clip(lin_pred, -100, 100))  \n    return np.sum(-lambda_ + Y * np.log(np.clip(lambda_, 1e-10, None)) - gammaln(Y + 1))\n  \ndef neg_loglik(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\ninitial_beta = np.zeros(X.shape[1])\nresult = optimize.minimize(\n    fun=neg_loglik,\n    x0=initial_beta,\n    args=(Y, X_matrix),\n    method='BFGS'\n)\n\nbeta_mle = result.x\nhessian_inv = result.hess_inv  \nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\nsummary = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': standard_errors\n}, index=X.columns)\n\nsummary\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.509992\n0.074991\n\n\nage\n0.148706\n0.004109\n\n\nage_squared\n-0.002972\n0.000101\n\n\niscustomer\n0.207609\n0.028164\n\n\nNortheast\n0.029155\n0.059189\n\n\nNorthwest\n-0.017578\n0.059060\n\n\nSouth\n0.056565\n0.066770\n\n\nSouthwest\n0.050567\n0.074074\n\n\n\n\n\n\n\nThrough finding the MLE vector and the Hessian of the Poisson model with covariates, above is the table of coefficients and standard errors for using the Hessain to find standard errors of the beta parameter estimates.\nC.\n\nimport statsmodels.api as sm\n\nglm_poisson = sm.GLM(Y, X, family=sm.families.Poisson())\nglm_result = glm_poisson.fit()\n\ncoeff_table = glm_result.summary2().tables[1]\nprint(coeff_table)\n\n                Coef.  Std.Err.          z         P&gt;|z|    [0.025    0.975]\nintercept   -0.508920  0.183179  -2.778269  5.464935e-03 -0.867944 -0.149896\nage          0.148619  0.013869  10.716250  8.539597e-27  0.121438  0.175801\nage_squared -0.002970  0.000258 -11.513237  1.131496e-30 -0.003476 -0.002465\niscustomer   0.207591  0.030895   6.719179  1.827509e-11  0.147037  0.268144\nNortheast    0.029170  0.043625   0.668647  5.037205e-01 -0.056334  0.114674\nNorthwest   -0.017575  0.053781  -0.326782  7.438327e-01 -0.122983  0.087833\nSouth        0.056561  0.052662   1.074036  2.828066e-01 -0.046655  0.159778\nSouthwest    0.050576  0.047198   1.071568  2.839141e-01 -0.041931  0.143083\n\n\nAnalysis for C:\nBy checking the poisson regression model results using sm.GLM() function, we find that age, age_squared, and customer status are statistically significant different from patent counts (p-value &lt; 0.05). As firm age increases, there are expected patent counts increase. Also, customers of Blueprinty tend to have significantly higher expected patent counts than non-customers. Additionally, regions are not satistically significant different from patent counts (p-value &gt; 0.05) when other variables are controlled.\nD.\n\nX_0 = X.copy()\nX_1 = X.copy()\n\nX_0['iscustomer'] = 0\nX_1['iscustomer'] = 1\n\ny_pred_0 = glm_result.predict(X_0)\ny_pred_1 = glm_result.predict(X_1)\n\neffect = y_pred_1 - y_pred_0\navg_effect = np.mean(effect)\n\nprint(\"Average predicted increase in patents from using Blueprinty software:\", avg_effect)\n\nAverage predicted increase in patents from using Blueprinty software: 0.7927680710452972\n\n\nAnalysis for D:\nBased on the poisson regression model, we can conclude that the usage of Blueprinty software is associated with an average increase of approximately 0.79 patents per firm."
  },
  {
    "objectID": "blog/project4/index.html#airbnb-case-study",
    "href": "blog/project4/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\nAssume the number of reviews is a good proxy for the number of bookings, then we performed some EDA for Airbnb data:\n\nfile_path_airbnb = \"airbnb.csv\" \ndf_airbnb = pd.read_csv(file_path_airbnb)\n\nsummary_info = df_airbnb.info()\nmissing_values = df_airbnb.isnull().sum()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\n\n\n\ndf_airbnb.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\nmissing_values\n\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\nRegarding the exploratory data analysis of the data, it shows that the relevant variables including host_since, bathrooms, review_scores_cleanliness, review_scores_location, review_scores_value have missing values within it. Then, we performed the handle of dropping these relevant variables’ missing values and built a poisson regression model for the number of bookings as proxied by the number of reviews.\n\nrelevant_vars = [\n    'number_of_reviews', 'room_type', 'bathrooms', 'bedrooms', 'price',\n    'review_scores_cleanliness', 'review_scores_location', 'review_scores_value',\n    'instant_bookable'\n]\ndf_clean = df_airbnb[relevant_vars].dropna()\n\n\ndf_clean = pd.get_dummies(df_clean, columns=['room_type', 'instant_bookable'], drop_first=True)\n\n\nX = df_clean.drop(columns=['number_of_reviews'])\nX = sm.add_constant(X)  # Add intercept\nY = df_clean['number_of_reviews']\n\nX = X.astype(float)\nY = Y.astype(float)\n\npoisson_model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()\n\ncoef_table = poisson_model.summary2().tables[1]\ncoef_table\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\n\n\nconst\n3.572486\n0.016005\n223.214538\n0.000000e+00\n3.541117\n3.603855\n\n\nbathrooms\n-0.123999\n0.003747\n-33.090794\n4.031530e-240\n-0.131344\n-0.116655\n\n\nbedrooms\n0.074941\n0.001988\n37.697741\n0.000000e+00\n0.071045\n0.078838\n\n\nprice\n-0.000014\n0.000008\n-1.728798\n8.384521e-02\n-0.000031\n0.000002\n\n\nreview_scores_cleanliness\n0.113187\n0.001493\n75.820487\n0.000000e+00\n0.110261\n0.116113\n\n\nreview_scores_location\n-0.076795\n0.001607\n-47.795559\n0.000000e+00\n-0.079944\n-0.073646\n\n\nreview_scores_value\n-0.091529\n0.001798\n-50.902050\n0.000000e+00\n-0.095053\n-0.088005\n\n\nroom_type_Private room\n-0.014535\n0.002737\n-5.310442\n1.093597e-07\n-0.019899\n-0.009170\n\n\nroom_type_Shared room\n-0.251896\n0.008618\n-29.228586\n8.404519e-188\n-0.268787\n-0.235005\n\n\ninstant_bookable_t\n0.334397\n0.002889\n115.747697\n0.000000e+00\n0.328734\n0.340059\n\n\n\n\n\n\n\nRegarding the model coefficients, we found that:\n\nInstant Bookable and Cleanliness both have the strongest positive association with the number of reviews.\nMore Bathrooms slightly decrease the number of reviews; however, more Bedrooms increase the number of reviews.\nPrice has small, marginally insignificant effect with the number of reviews.\nHigher location scores decrease the number of reviews; meanwhile, higher value scores also decrease the number of reviews.\nPrivate rooms get few reviews than the entire home/apt; meanwhile, shared rooms get much fewer reviews than the entire home/apt."
  }
]